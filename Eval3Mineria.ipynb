{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMbq7Phf/gs2XNAiHUFOUV7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Medalcode/Colab1/blob/main/Eval3Mineria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Avance para Retroalimentación Evaluacion 3 Mineria de Datos**\n",
        "\n",
        "# **Integrantes: Camila Troncoso - Jonatthan Medalla**"
      ],
      "metadata": {
        "id": "lyG5V24P2psH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # Importa la librería pandas para manipulación de datos (DataFrames).\n",
        "import numpy as np # Importa la librería numpy para operaciones numéricas.\n",
        "import io # Módulo para trabajar con streams de I/O.\n",
        "import base64 # Módulo para codificación y decodificación Base64.\n",
        "import matplotlib.pyplot as plt # Importa matplotlib para la creación de gráficos.\n",
        "import seaborn as sns # Importa seaborn para visualizaciones estadísticas, basado en matplotlib.\n",
        "import gradio as gr # Importa Gradio para construir interfaces de usuario interactivas.\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler # Importa escaladores para normalización y estandarización.\n",
        "from scipy.stats import skew, kurtosis # Importa funciones para calcular asimetría y curtosis.\n",
        "import os # Módulo para interactuar con el sistema operativo (e.g., rutas de archivos).\n",
        "from io import BytesIO # Clase para manejar streams de bytes en memoria.\n",
        "\n",
        "# Install missing dependency\n",
        "!pip install rfc3987 # Instala la librería rfc3987, necesaria para algunas funcionalidades de Gradio o sus dependencias."
      ],
      "metadata": {
        "id": "RpE9s8Db2rTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31f619e-c145-48df-b314-80ffd9aa468f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rfc3987 in /usr/local/lib/python3.12/dist-packages (1.3.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración inicial para Matplotlib/Seaborn\n",
        "sns.set_theme(style=\"whitegrid\") # Establece un tema visual para Seaborn con un fondo de cuadrícula blanco."
      ],
      "metadata": {
        "id": "WlHdnscqyqOW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables globales para almacenar el DataFrame y el historial de operaciones (Log)\n",
        "estado_df = None # Variable global para mantener el DataFrame actual procesado.\n",
        "entradas_log = [] # Lista global para registrar las operaciones realizadas en el DataFrame."
      ],
      "metadata": {
        "id": "FgL05IKHyjdk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_columnas_numericas(df_entrada):\n",
        "    \"\"\"Función auxiliar para obtener columnas numéricas de un DataFrame.\"\"\"\n",
        "    if df_entrada is not None:\n",
        "        # Selecciona columnas con tipos de datos numéricos y retorna sus nombres como una lista.\n",
        "        return df_entrada.select_dtypes(include=np.number).columns.tolist()\n",
        "    return [] # Retorna una lista vacía si el DataFrame es None."
      ],
      "metadata": {
        "id": "ftLC_yuEyzXA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3EC33s5blKY"
      },
      "source": [
        "def cargar_datos(archivo_obj, delimitador_elegido):\n",
        "    \"\"\"I.1 cargar_datos: Carga el archivo subido en un DataFrame de pandas.\"\"\"\n",
        "    global estado_df, entradas_log # Accede a las variables globales estado_df y entradas_log.\n",
        "    entradas_log = [] # Reinicia el log en cada nueva carga para mantener un historial limpio de la sesión actual.\n",
        "\n",
        "    if archivo_obj is None:\n",
        "        return None, \"Error: Debe subir un archivo.\", None # Si no hay archivo, retorna un error.\n",
        "\n",
        "    ruta_archivo = archivo_obj.name # Obtiene la ruta física del archivo subido.\n",
        "\n",
        "    try:\n",
        "        # Procesa archivos CSV\n",
        "        if ruta_archivo.endswith('.csv'):\n",
        "            # Determina el delimitador basado en la selección del usuario.\n",
        "            if delimitador_elegido == \"Coma (,)\":\n",
        "                delimitador = ','\n",
        "            elif delimitador_elegido == \"Punto y Coma (;)\":\n",
        "                delimitador = ';'\n",
        "            else:\n",
        "                delimitador = ',' # Delimitador por defecto si no se especifica o es inválido.\n",
        "\n",
        "            # Intentar leer el archivo con codificaciones comunes para manejar diferentes formatos.\n",
        "            try:\n",
        "                df_datos = pd.read_csv(ruta_archivo, delimiter=delimitador, encoding='utf-8')\n",
        "            except UnicodeDecodeError:\n",
        "                df_datos = pd.read_csv(ruta_archivo, delimiter=delimitador, encoding='ISO-8859-1')\n",
        "\n",
        "            # ***** NUEVA LÓGICA: Detección de CSV de una sola columna *****\n",
        "            if df_datos.shape[1] == 1: # Verifica si el DataFrame tiene solo una columna.\n",
        "                estado_df = None # Reinicia el DataFrame de estado.\n",
        "                # Retorna un error si el CSV tiene una sola columna, sugiriendo un delimitador incorrecto.\n",
        "                return None, \"Error: El archivo CSV cargado tiene una sola columna. Asegúrese de seleccionar el delimitador correcto o que el archivo contenga múltiples columnas para un análisis significativo.\", None\n",
        "            # ************************************************************\n",
        "\n",
        "        # Procesa archivos Excel (xls o xlsx)\n",
        "        elif ruta_archivo.endswith(('.xls', '.xlsx')):\n",
        "            df_datos = pd.read_excel(ruta_archivo) # Lee el archivo Excel.\n",
        "\n",
        "        # Maneja tipos de archivo no soportados.\n",
        "        else:\n",
        "            return None, \"Error: Archivo no válido. Suba un archivo CSV o Excel.\", None # Retorna un error para tipos de archivo no soportados.\n",
        "\n",
        "        # Validación de tipos de datos: verifica que el DataFrame contenga columnas categóricas y numéricas.\n",
        "        columnas_numericas = df_datos.select_dtypes(include=np.number).columns\n",
        "        columnas_categoricas = df_datos.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "        # Genera un mensaje de advertencia si faltan tipos de datos importantes para el análisis.\n",
        "        if len(columnas_numericas) == 0 or len(columnas_categoricas) == 0:\n",
        "            mensaje = \"Advertencia: El archivo debe contener tanto datos categóricos como numéricos para un análisis completo.\"\n",
        "        else:\n",
        "            mensaje = f\"Archivo cargado. Dimensiones: {df_datos.shape}. {len(columnas_numericas)} numéricas, {len(columnas_categoricas)} categóricas.\"\n",
        "\n",
        "        estado_df = df_datos # Almacena el DataFrame cargado en la variable de estado global.\n",
        "        # Registra la operación de carga en el log.\n",
        "        entradas_log.append(f\"Carga: Archivo {os.path.basename(ruta_archivo)} cargado. Se detectaron {df_datos.shape[0]} filas.\")\n",
        "\n",
        "        # Retorna el DataFrame, el mensaje y una vista previa de las primeras filas.\n",
        "        return estado_df, mensaje, gr.Dataframe(value=df_datos.head())\n",
        "\n",
        "    except Exception as e:\n",
        "        estado_df = None # Reinicia el DataFrame de estado si ocurre un error.\n",
        "        return None, f\"Error de lectura: {str(e)}\", None # Retorna un mensaje de error detallado."
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def manejar_valores_nulos(df_entrada, nombres_columnas_str, metodo):\n",
        "    \"\"\"II.1 manejar_valores_nulos: Manejo interactivo de valores nulos utilizando diferentes estrategias.\"\"\"\n",
        "    global estado_df, entradas_log # Accede a las variables globales.\n",
        "    # Crea una copia del DataFrame de entrada para no modificar el original directamente hasta que la operación se confirme.\n",
        "    df_procesado = df_entrada.copy() if df_entrada is not None else None\n",
        "\n",
        "    # Verifica si hay un DataFrame cargado; si no, retorna un error.\n",
        "    if df_procesado is None:\n",
        "        return None, \"Error: Primero cargue un archivo.\", None\n",
        "\n",
        "    # Procesa la cadena de nombres de columnas para obtener una lista, eliminando espacios en blanco.\n",
        "    nombres_columnas = [c.strip() for c in nombres_columnas_str.split(\",\") if c.strip()]\n",
        "    if not nombres_columnas:\n",
        "        # Si el usuario no especificó columnas, aplicar a todas las columnas numéricas automáticamente.\n",
        "        nombres_columnas = get_columnas_numericas(df_procesado)\n",
        "        if not nombres_columnas:\n",
        "            return estado_df, \"Advertencia: No hay columnas numéricas para aplicar la limpieza de nulos.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Calcula el número total de valores nulos antes del tratamiento en las columnas seleccionadas.\n",
        "    total_nulos_previos = df_procesado[nombres_columnas].isnull().sum().sum()\n",
        "    filas_afectadas = 0 # Inicializa el contador de filas o valores afectados.\n",
        "\n",
        "    # Si no hay nulos en las columnas seleccionadas, no se realiza ninguna operación.\n",
        "    if total_nulos_previos == 0:\n",
        "        mensaje = \"No se encontraron valores nulos en las columnas seleccionadas. No se realizó ninguna operación.\"\n",
        "        return estado_df, mensaje, gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Aplica el método de \"Eliminar filas\" si es seleccionado.\n",
        "    if metodo == \"Eliminar filas\":\n",
        "        total_filas_originales = len(df_procesado)\n",
        "        df_procesado = df_procesado.dropna(subset=nombres_columnas) # Elimina filas con nulos en las columnas especificadas.\n",
        "        filas_afectadas = total_filas_originales - len(df_procesado) # Calcula cuántas filas fueron eliminadas.\n",
        "        # Registra la operación en el log.\n",
        "        entradas_log.append(f\"Limpieza Nulos: Se eliminaron {filas_afectadas} filas con nulos en {', '.join(nombres_columnas)}.\")\n",
        "\n",
        "    else:\n",
        "        # Itera sobre cada columna para aplicar los métodos de imputación.\n",
        "        for col in nombres_columnas:\n",
        "            # Verifica si la columna existe y es numérica antes de imputar.\n",
        "            if col not in df_procesado.columns or col not in get_columnas_numericas(df_procesado):\n",
        "                entradas_log.append(f\"Advertencia: La columna '{col}' no es numérica o no existe para imputación. Se omitió.\")\n",
        "                continue\n",
        "\n",
        "            valor_imputacion = 0 # Valor por defecto para evitar errores si no se selecciona un método válido.\n",
        "            # Determina el valor de imputación según el método seleccionado.\n",
        "            if metodo == \"Llenar con promedio\":\n",
        "                valor_imputacion = df_procesado[col].mean() # Imputa con la media de la columna.\n",
        "            elif metodo == \"Llenar con máximo\":\n",
        "                valor_imputacion = df_procesado[col].max() # Imputa con el valor máximo de la columna.\n",
        "            elif metodo == \"Llenar con mínimo\":\n",
        "                valor_imputacion = df_procesado[col].min() # Imputa con el valor mínimo de la columna.\n",
        "            elif metodo == \"Llenar con cero\":\n",
        "                valor_imputacion = 0 # Imputa con cero.\n",
        "\n",
        "            nulos_en_columna = df_procesado[col].isnull().sum() # Cuenta los nulos en la columna actual.\n",
        "            df_procesado[col] = df_procesado[col].fillna(valor_imputacion) # Rellena los nulos con el valor calculado.\n",
        "            filas_afectadas += nulos_en_columna # Suma los nulos que realmente se llenaron.\n",
        "            # Registra la operación en el log.\n",
        "            entradas_log.append(f\"Limpieza Nulos: La columna '{col}' se imputó con {metodo.split(' ')[-1]} ({valor_imputacion:.2f}).\")\n",
        "\n",
        "    # Actualiza el DataFrame de estado global con el DataFrame procesado.\n",
        "    estado_df = df_procesado\n",
        "    # Prepara el mensaje de éxito para el usuario.\n",
        "    mensaje = f\"Limpieza completada. {total_nulos_previos} valores nulos tratados. Registros afectados: {filas_afectadas}.\"\n",
        "    # Retorna el DataFrame actualizado, el mensaje y una vista previa.\n",
        "    return estado_df, mensaje, gr.Dataframe(value=estado_df.head())"
      ],
      "metadata": {
        "id": "ycg3E7sYzAE9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aplicar_escalado(df_entrada, nombres_columnas_str, metodo_escalado):\n",
        "    \"\"\"II.2 aplicar_escalado: Aplica normalización (Min-Max) o estandarización (Z-Score) a columnas numéricas.\"\"\"\n",
        "    global estado_df, entradas_log # Accede a las variables globales.\n",
        "    # Crea una copia del DataFrame de entrada para evitar modificar el original directamente.\n",
        "    df_escalado = df_entrada.copy() if df_entrada is not None else None\n",
        "\n",
        "    # Verifica si hay un DataFrame cargado; si no, retorna un error.\n",
        "    if df_escalado is None:\n",
        "        return None, \"Error: Primero cargue un archivo.\", None\n",
        "\n",
        "    # Procesa la cadena de nombres de columnas para obtener una lista de columnas a escalar.\n",
        "    nombres_columnas = [c.strip() for c in nombres_columnas_str.split(\",\") if c.strip()]\n",
        "    # Si no se especifican columnas, se retorna un error.\n",
        "    if not nombres_columnas:\n",
        "        return estado_df, \"Error: Debe especificar al menos una columna numérica para escalar.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Valida que todas las columnas especificadas existan y sean numéricas.\n",
        "    if not all(col in df_escalado.columns and col in get_columnas_numericas(df_escalado) for col in nombres_columnas):\n",
        "        return estado_df, \"Error: Verifique que las columnas existan y sean numéricas.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    escalador = None # Inicializa la variable del escalador.\n",
        "    justificacion_escalado = \"\" # Inicializa la justificación del escalado.\n",
        "    # Selecciona el escalador y la justificación según el método elegido.\n",
        "    if metodo_escalado == \"Min-Max\":\n",
        "        escalador = MinMaxScaler() # Utiliza MinMaxScaler para normalización (rango [0, 1]).\n",
        "        justificacion_escalado = \"**Recomendación Min-Max:** Se recomienda para algoritmos que esperan un rango acotado (ej. Redes Neuronales) o cuando la distribución no es gaussiana. Sin embargo, es sensible a los *outliers* [10-12].\"\n",
        "    elif metodo_escalado == \"Z-Score\":\n",
        "        escalador = StandardScaler() # Utiliza StandardScaler para estandarización (media 0, desviación estándar 1).\n",
        "        justificacion_escalado = \"**Recomendación Z-Score:** Se recomienda para algoritmos basados en distancias (ej. K-Means, KNN) o cuando se asume una distribución aproximadamente normal. Es menos sensible a los *outliers* que Min-Max [10, 12, 13].\"\n",
        "    else:\n",
        "        return estado_df, \"Método de escalado no válido.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Aplica el escalado a cada columna seleccionada.\n",
        "    for col in nombres_columnas:\n",
        "        # Transforma la columna usando el escalador elegido. Se usa [[col]] para mantener la dimensión 2D requerida por fit_transform.\n",
        "        df_escalado[col] = escalador.fit_transform(df_escalado[[col]])\n",
        "        entradas_log.append(f\"Escalado: Columna '{col}' escalada usando {metodo_escalado}.\") # Registra la operación en el log.\n",
        "\n",
        "    estado_df = df_escalado # Actualiza el DataFrame de estado global con el DataFrame escalado.\n",
        "    # Prepara el mensaje de éxito para el usuario.\n",
        "    mensaje = f\"Escalado de {', '.join(nombres_columnas)} completado usando {metodo_escalado}. {justificacion_escalado}\"\n",
        "    # Retorna el DataFrame actualizado, el mensaje y una vista previa.\n",
        "    return estado_df, mensaje, gr.Dataframe(value=estado_df.head())"
      ],
      "metadata": {
        "id": "AeIOVC8gzpIK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detectar_y_tratar_outliers(df_entrada, nombre_columna, tratamiento):\n",
        "    \"\"\"II.3 detectar_y_tratar_outliers: Detección de valores atípicos (outliers) por el método IQR y aplicación de tratamientos.\"\"\"\n",
        "    global estado_df, entradas_log # Accede a las variables globales.\n",
        "    # Crea una copia del DataFrame de entrada para evitar modificar el original directamente.\n",
        "    df_outliers_tratado = df_entrada.copy() if df_entrada is not None else None\n",
        "\n",
        "    # Verifica si hay un DataFrame cargado; si no, retorna un error.\n",
        "    if df_outliers_tratado is None:\n",
        "        return None, \"Error: Primero cargue un archivo.\", None\n",
        "\n",
        "    # Valida que la columna especificada exista y sea numérica.\n",
        "    if nombre_columna not in df_outliers_tratado.columns or nombre_columna not in get_columnas_numericas(df_outliers_tratado):\n",
        "        return estado_df, f\"Error: La columna '{nombre_columna}' no existe o no es numérica.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Calcula los cuartiles (Q1 y Q3) de la columna para el método IQR (Rango Intercuartílico).\n",
        "    cuartil_1 = df_outliers_tratado[nombre_columna].quantile(0.25)\n",
        "    cuartil_3 = df_outliers_tratado[nombre_columna].quantile(0.75)\n",
        "    # Calcula el Rango Intercuartílico (IQR).\n",
        "    rango_iqr = cuartil_3 - cuartil_1\n",
        "    # Define los límites inferior y superior para la detección de outliers (1.5 * IQR).\n",
        "    limite_inferior_iqr = cuartil_1 - 1.5 * rango_iqr\n",
        "    limite_superior_iqr = cuartil_3 + 1.5 * rango_iqr\n",
        "\n",
        "    # Identifica los registros que son outliers (fuera de los límites IQR).\n",
        "    registros_outliers = df_outliers_tratado[(df_outliers_tratado[nombre_columna] < limite_inferior_iqr) | (df_outliers_tratado[nombre_columna] > limite_superior_iqr)]\n",
        "    numero_outliers = len(registros_outliers)\n",
        "\n",
        "    # Si no se detectan outliers, informa al usuario y no realiza ninguna acción.\n",
        "    if numero_outliers == 0:\n",
        "        mensaje = f\"No se detectaron *outliers* en la columna '{nombre_columna}' (Método IQR).\"\n",
        "        return estado_df, mensaje, gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Aplica el tratamiento seleccionado por el usuario.\n",
        "    if tratamiento == \"Eliminar registros\":\n",
        "        # Filtra el DataFrame para eliminar las filas que contienen outliers.\n",
        "        df_outliers_tratado = df_outliers_tratado[~((df_outliers_tratado[nombre_columna] < limite_inferior_iqr) | (df_outliers_tratado[nombre_columna] > limite_superior_iqr))]\n",
        "        # Registra la operación en el log.\n",
        "        entradas_log.append(f\"Outliers: Se eliminaron {numero_outliers} *outliers* en '{nombre_columna}'.\")\n",
        "        mensaje = f\"Se detectaron y eliminaron {numero_outliers} *outliers* en '{nombre_columna}'. Se eliminaron {numero_outliers} filas.\"\n",
        "\n",
        "    elif tratamiento == \"Capping (Winsorización)\":\n",
        "        # Limita los valores atípicos a los umbrales IQR (Winsorización).\n",
        "        df_outliers_tratado[nombre_columna] = np.where(df_outliers_tratado[nombre_columna] > limite_superior_iqr, limite_superior_iqr, df_outliers_tratado[nombre_columna])\n",
        "        df_outliers_tratado[nombre_columna] = np.where(df_outliers_tratado[nombre_columna] < limite_inferior_iqr, limite_inferior_iqr, df_outliers_tratado[nombre_columna])\n",
        "        # Registra la operación en el log.\n",
        "        entradas_log.append(f\"Outliers: Se aplicó *capping* a {numero_outliers} *outliers* en '{nombre_columna}'.\")\n",
        "        mensaje = f\"Se detectaron {numero_outliers} *outliers* y se aplicó *Capping* (Winsorización) para conservar los registros.\"\n",
        "\n",
        "    else: # Opción \"Informar\" (no modifica el DataFrame)\n",
        "        # Simplemente informa sobre la presencia de outliers sin modificarlos.\n",
        "        mensaje = f\"Se detectaron {numero_outliers} *outliers* en '{nombre_columna}'. Se recomienda tratarlos, ya que pueden sesgar la media y la desviación estándar [15, 21].\"\n",
        "        estado_df = df_entrada # No se modifica el DataFrame si solo se informa.\n",
        "        return estado_df, mensaje, gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Actualiza el DataFrame de estado global con el DataFrame procesado.\n",
        "    estado_df = df_outliers_tratado\n",
        "    # Retorna el DataFrame actualizado, el mensaje y una vista previa.\n",
        "    return estado_df, mensaje, gr.Dataframe(value=estado_df.head())"
      ],
      "metadata": {
        "id": "rMskprKR0Joo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ejecutar_analisis(df_entrada):\n",
        "    \"\"\"III.1 ejecutar_analisis: Calcula estadísticas descriptivas, correlación, curtosis y asimetría de las columnas numéricas.\"\"\"\n",
        "    global entradas_log # Accede a la variable global de registro.\n",
        "    # Verifica si hay un DataFrame cargado; si no, retorna un error.\n",
        "    if df_entrada is None:\n",
        "        return \"Error: Primero cargue y procese el archivo.\", None\n",
        "\n",
        "    # Selecciona solo las columnas numéricas del DataFrame para el análisis.\n",
        "    df_numerico = df_entrada.select_dtypes(include=np.number)\n",
        "\n",
        "    # Verifica si existen columnas numéricas en el DataFrame.\n",
        "    if df_numerico.empty:\n",
        "        return \"El DataFrame no contiene columnas numéricas para el análisis estadístico.\", None\n",
        "\n",
        "    # Calcula las estadísticas descriptivas (media, desviación estándar, cuartiles, etc.).\n",
        "    estadisticas_descriptivas = df_numerico.describe().T\n",
        "    # Calcula la matriz de correlación de Pearson entre las columnas numéricas.\n",
        "    matriz_correlacion = df_numerico.corr(method='pearson')\n",
        "\n",
        "    # Calcula la curtosis de cada columna numérica (Fisher=False para que la normal sea 3).\n",
        "    series_curtosis = df_numerico.apply(kurtosis, fisher=False)\n",
        "    # Calcula la asimetría (skewness) de cada columna numérica.\n",
        "    series_asimetria = df_numerico.apply(skew)\n",
        "\n",
        "    # Combina los resultados de curtosis y asimetría en un solo DataFrame.\n",
        "    df_forma_distribucion = pd.DataFrame({\n",
        "        'Curtosis (Normal ≈ 3)': series_curtosis,\n",
        "        'Asimetría (Skewness)': series_asimetria\n",
        "    }).round(3)\n",
        "\n",
        "    # Prepara el texto de interpretación de los resultados.\n",
        "    texto_interpretacion = \"### Resumen de Interpretación:\\n\"\n",
        "    texto_interpretacion += \"- **Curtosis:** Los valores > 3 (Leptocúrtica) indican un pico más agudo y colas pesadas, sugiriendo más *outliers* [30].\\n\"\n",
        "    texto_interpretacion += \"- **Asimetría:** Valores positivos (> 0) indican sesgo a la derecha (media > mediana) [29, 31].\\n\"\n",
        "    texto_interpretacion += \"- **Correlación:** Los valores cercanos a 1 o -1 en el mapa de calor indican relaciones lineales fuertes entre pares de variables [32].\\n\"\n",
        "\n",
        "    # Registra la operación de análisis en el log.\n",
        "    entradas_log.append(\"Análisis Estadístico: Cálculos descriptivos, curtosis y asimetría generados.\")\n",
        "\n",
        "    # Formatea el resumen del análisis para mostrarlo al usuario.\n",
        "    resumen_analisis_texto = (\n",
        "        f\"{texto_interpretacion}\\n\\n\"\n",
        "        f\"**Estadísticas Descriptivas (Media, Desviación, Cuartiles):**\\n{estadisticas_descriptivas.to_markdown()}\\n\\n\"\n",
        "        f\"**Forma de la Distribución (Curtosis y Asimetría):**\\n{df_forma_distribucion.to_markdown()}\\n\"\n",
        "    )\n",
        "\n",
        "    # Retorna el resumen en texto y la matriz de correlación (esta última para posible uso interno o visualización).\n",
        "    return resumen_analisis_texto, matriz_correlacion"
      ],
      "metadata": {
        "id": "2Ddj2wqk0oYW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_graficos(df_entrada, columna_correlacion_heatmap, columna_distribucion_plot):\n",
        "    \"\"\"III.2 generar_graficos: Genera un mapa de calor de correlaciones y un histograma/boxplot para una columna seleccionada.\"\"\"\n",
        "    global entradas_log # Accede a la variable global de registro.\n",
        "\n",
        "    # Verifica si hay un DataFrame cargado; si no, retorna un error.\n",
        "    if df_entrada is None:\n",
        "        return None, None, \"Error: Primero cargue el archivo.\"\n",
        "\n",
        "    # Selecciona solo las columnas numéricas del DataFrame para la generación de gráficos.\n",
        "    df_numerico = df_entrada.select_dtypes(include=np.number)\n",
        "\n",
        "    # Si no hay columnas numéricas, advierte al usuario.\n",
        "    if df_numerico.empty:\n",
        "        return None, None, \"Advertencia: No hay columnas numéricas para generar gráficos.\"\n",
        "\n",
        "    ruta_plot_correlacion = None\n",
        "    ruta_plot_distribucion = None\n",
        "\n",
        "    try:\n",
        "        # Crea una figura para el mapa de calor de correlaciones.\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        # Genera el mapa de calor usando Seaborn, mostrando los valores de correlación y una paleta de color.\n",
        "        sns.heatmap(df_numerico.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "        plt.title(\"Mapa de Calor de Correlaciones (Pearson)\")\n",
        "        # Guarda el mapa de calor como una imagen PNG.\n",
        "        ruta_plot_correlacion = \"correlation_plot.png\"\n",
        "        plt.savefig(ruta_plot_correlacion)\n",
        "        plt.close() # Cierra la figura para liberar memoria.\n",
        "        entradas_log.append(\"Visualización: Mapa de calor de correlaciones generado.\") # Registra la operación.\n",
        "    except Exception as e:\n",
        "        entradas_log.append(f\"Error al generar mapa de correlación: {e}\") # Registra cualquier error que ocurra.\n",
        "\n",
        "    # Verifica si se ha especificado una columna para el gráfico de distribución y si esta es numérica.\n",
        "    if columna_distribucion_plot and columna_distribucion_plot in df_numerico.columns:\n",
        "        try:\n",
        "            # Crea una figura con dos subplots para el histograma y el boxplot.\n",
        "            figura, ejes = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
        "\n",
        "            # Genera un histograma con la función de densidad de kernel (KDE) para mostrar la distribución.\n",
        "            sns.histplot(df_numerico[columna_distribucion_plot], kde=True, ax=ejes[0])\n",
        "            ejes[0].set_title(f\"Distribución de: {columna_distribucion_plot} (Histograma y KDE)\")\n",
        "\n",
        "            # Genera un boxplot para visualizar la distribución, la mediana y los posibles outliers (valores atípicos).\n",
        "            sns.boxplot(x=df_numerico[columna_distribucion_plot], ax=ejes[1])\n",
        "            ejes[1].set_title(f\"Boxplot de: {columna_distribucion_plot} (Outliers: 1.5*IQR)\")\n",
        "\n",
        "            plt.tight_layout() # Ajusta el diseño para evitar superposiciones entre subplots.\n",
        "            # Guarda los gráficos de distribución como una imagen PNG.\n",
        "            ruta_plot_distribucion = \"distribution_plot.png\"\n",
        "            plt.savefig(ruta_plot_distribucion)\n",
        "            plt.close() # Cierra la figura para liberar memoria.\n",
        "            entradas_log.append(f\"Visualización: Gráfico de distribución para '{columna_distribucion_plot}' generado.\") # Registra la operación.\n",
        "        except Exception as e:\n",
        "            entradas_log.append(f\"Error al generar gráfico de distribución para '{columna_distribucion_plot}': {e}\") # Registra cualquier error.\n",
        "    else:\n",
        "        entradas_log.append(\"Advertencia: No se pudo generar el gráfico de distribución, columna no numérica o inexistente.\")\n",
        "\n",
        "    # Retorna las rutas de los archivos generados y un mensaje de estado.\n",
        "    return ruta_plot_correlacion, ruta_plot_distribucion, \"Gráficos generados correctamente.\" if ruta_plot_correlacion or ruta_plot_distribucion else \"No se pudo generar ningón gráfico.\"\n"
      ],
      "metadata": {
        "id": "LvVmgYiU02DD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exportar_resultados(df_entrada, formato_exportacion):\n",
        "    \"\"\"IV.1 exportar_resultados: Permite la exportación del DataFrame procesado y genera un reporte de log de las operaciones.\"\"\"\n",
        "    global entradas_log # Accede a la variable global de registro.\n",
        "\n",
        "    # Verifica si hay un DataFrame procesado; si no, retorna un error.\n",
        "    if df_entrada is None:\n",
        "        return \"Error: No hay datos procesados para exportar.\", None, None\n",
        "\n",
        "    ruta_reporte = \"reporte_analisis.txt\" # Define el nombre del archivo del reporte de log.\n",
        "    contenido_log = \"\\n\".join(entradas_log) # Concatena todas las entradas del log en una cadena, separadas por saltos de línea.\n",
        "\n",
        "    # Prepara el contenido final del reporte incluyendo un resumen automático y la interpretación.\n",
        "    contenido_reporte_final = (\n",
        "        \"### REPORTE BREVE AUTOMÁTICO DE PROCESAMIENTO DE DATOS\\n\\n\"\n",
        "        \"**Proceso Seguido y Decisiones Tomadas en Limpieza de Datos:**\\n\"\n",
        "        f\"{contenido_log}\\n\\n\"\n",
        "        f\"**Interpretación Preliminar de Resultados Obtenidos:**\\n\"\n",
        "        f\"(La interpretación completa de correlaciones, curtosis y regresiones debe realizarla el analista.)\\n\"\n",
        "        f\"Se recomienda revisar el *heatmap* para correlaciones fuertes (Pearson > 0.7 o < -0.7) [32, 38].\\n\"\n",
        "        f\"La limpieza de datos asegura la calidad y reduce el sesgo en fases de modelado posteriores (GIGO: *Garbage In, Garbage Out*) [39].\\n\"\n",
        "        f\"Dimensiones del DataFrame final: {df_entrada.shape}\\n\"\n",
        "    )\n",
        "\n",
        "    # Escribe el contenido del reporte en un archivo de texto.\n",
        "    with open(ruta_reporte, \"w\") as f:\n",
        "        f.write(contenido_reporte_final)\n",
        "\n",
        "    ruta_salida = None # Inicializa la ruta del archivo de datos procesados.\n",
        "    # Exporta el DataFrame procesado según el formato seleccionado por el usuario.\n",
        "    if formato_exportacion == \"CSV\":\n",
        "        ruta_salida = \"datos_procesados.csv\"\n",
        "        df_entrada.to_csv(ruta_salida, index=False) # Exporta a CSV sin el índice del DataFrame.\n",
        "    elif formato_exportacion == \"Excel\":\n",
        "        ruta_salida = \"datos_procesados.xlsx\"\n",
        "        df_entrada.to_excel(ruta_salida, index=False) # Exporta a Excel sin el índice del DataFrame.\n",
        "    else:\n",
        "        return \"Error: Formato de exportación no válido.\", None, None # Retorna un error si el formato no es válido.\n",
        "\n",
        "    # Registra la operación de exportación en el log.\n",
        "    entradas_log.append(f\"Exportación: Datos procesados guardados en {ruta_salida} y Log generado.\")\n",
        "\n",
        "    # Retorna un mensaje de éxito, la ruta del archivo de datos y la ruta del reporte.\n",
        "    return f\"Exportación exitosa. Descargue el archivo y el reporte.\", ruta_salida, ruta_reporte"
      ],
      "metadata": {
        "id": "diuCV09P0_4E"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_dropdown_choices(df_entrada):\n",
        "    \"\"\"Actualiza las opciones del dropdown de columnas numéricas en la interfaz de Gradio, útil después de operaciones que pueden cambiar las columnas.\"\"\"\n",
        "    if df_entrada is not None:\n",
        "        # Asume que get_columnas_numericas ya está definida en otra celda y accesible.\n",
        "        numeric_cols = get_columnas_numericas(df_entrada) # Obtiene la lista de columnas numéricas del DataFrame actual.\n",
        "        # Retorna un componente Dropdown actualizado con las columnas numéricas como opciones.\n",
        "        # Si hay columnas, selecciona la primera por defecto; de lo contrario, deja el valor en None.\n",
        "        return gr.Dropdown(choices=numeric_cols, value=numeric_cols[0] if numeric_cols else None)\n",
        "    # Si no hay DataFrame, retorna un Dropdown vacío.\n",
        "    return gr.Dropdown(choices=[], value=None)"
      ],
      "metadata": {
        "id": "u4L9w-yoA78Z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr # Importa la librería Gradio para construir la interfaz de usuario.\n",
        "\n",
        "# Define la interfaz de Gradio como un bloque, con un título principal.\n",
        "with gr.Blocks(title=\"Aplicación de Minería de Datos y EDA\") as interfaz:\n",
        "    gr.Markdown(\"## \\U0001f528️ Aplicación Interactiva para Procesamiento y Análisis de Datos\") # Título principal de la aplicación.\n",
        "\n",
        "    estado_df_gradio = gr.State(None) # Un componente de estado de Gradio para mantener el DataFrame entre interacciones, sin mostrarlo directamente.\n",
        "\n",
        "    # Define la primera pestaña para la carga de datos.\n",
        "    with gr.Tab(\"1. Carga de Datos\"):\n",
        "        gr.Markdown(\"### Carga y Validación del Archivo\") # Subtítulo para la sección de carga.\n",
        "        with gr.Row(): # Organiza los componentes en una fila.\n",
        "            # Componente para subir el archivo (CSV o Excel).\n",
        "            input_archivo = gr.File(label=\"Subir Archivo (CSV o Excel)\", interactive=True)\n",
        "            # Radio buttons para seleccionar el delimitador del archivo CSV.\n",
        "            radio_separador = gr.Radio(\n",
        "                choices=[\"Coma (,)\", \"Punto y Coma (;)\"],\n",
        "                label=\"Selecciona el Separador del Archivo\",\n",
        "                value=\"Coma (,)\",\n",
        "                interactive=True\n",
        "            )\n",
        "\n",
        "        btn_cargar_datos = gr.Button(\"Cargar y Validar\") # Botón para iniciar la carga de datos.\n",
        "        msg_carga_datos = gr.Textbox(label=\"Mensaje de Carga\") # Muestra mensajes de estado de la carga.\n",
        "        df_vista_previa = gr.Dataframe(label=\"Vista Previa (5 primeras filas)\") # Muestra las primeras filas del DataFrame cargado.\n",
        "\n",
        "    # Define la segunda pestaña para el procesamiento y limpieza de datos.\n",
        "    with gr.Tab(\"2. Procesamiento y Limpieza (Preparación de Datos)\"):\n",
        "        gr.Markdown(\"### Limpieza de Valores Nulos\") # Subtítulo para la sección de nulos.\n",
        "        with gr.Row(): # Organiza los componentes en una fila.\n",
        "            radio_metodo_nulos = gr.Radio(\n",
        "                choices=[\"Eliminar filas\", \"Llenar con promedio\", \"Llenar con máximo\", \"Llenar con mínimo\", \"Llenar con cero\"],\n",
        "                label=\"Método para manejar nulos [6, 41]\",\n",
        "                value=\"Eliminar filas\"\n",
        "            )\n",
        "            input_col_nulos = gr.Textbox(label=\"Columnas para Limpieza (Separadas por comas)\", placeholder=\"Ej: Col1, Col2 (Dejar vacío para todo el DF)\")\n",
        "\n",
        "        btn_aplicar_nulos = gr.Button(\"Aplicar Limpieza de Nulos\") # Botón para aplicar la limpieza de nulos.\n",
        "        msg_resultado_nulos = gr.Textbox(label=\"Resultado Nulos\") # Muestra el resultado de la operación de nulos.\n",
        "\n",
        "        gr.Markdown(\"### Normalización y Estandarización\") # Subtítulo para la sección de escalado.\n",
        "        with gr.Row(): # Organiza los componentes en una fila.\n",
        "            radio_metodo_escalado = gr.Radio(\n",
        "                choices=[\"Min-Max\", \"Z-Score\"],\n",
        "                label=\"Método de Escalado [10, 42]\",\n",
        "                value=\"Z-Score\"\n",
        "            )\n",
        "            input_col_escalar = gr.Textbox(label=\"Columnas Numéricas para Escalar (Separadas por comas)\", placeholder=\"Ej: Edad, Salario\")\n",
        "\n",
        "        btn_aplicar_escalado = gr.Button(\"Aplicar Normalización / Estandarización\") # Botón para aplicar el escalado.\n",
        "        msg_resultado_escalado = gr.Textbox(label=\"Resultado Normalización y Justificación [10]\") # Muestra el resultado del escalado.\n",
        "\n",
        "        gr.Markdown(\"### Detección y Tratamiento de Outliers (IQR)\") # Subtítulo para la sección de outliers.\n",
        "        with gr.Row(): # Organiza los componentes en una fila.\n",
        "            input_col_outliers = gr.Textbox(label=\"Columna para Detección de Outliers (Una sola columna)\", placeholder=\"Ej: Ingresos\")\n",
        "            radio_tratamiento_outliers = gr.Radio(\n",
        "                choices=[\"Informar\", \"Eliminar registros\", \"Capping (Winsorización)\"],\n",
        "                label=\"Tratamiento de Outliers [10, 19, 20]\",\n",
        "                value=\"Informar\"\n",
        "            )\n",
        "\n",
        "        btn_detectar_outliers = gr.Button(\"Detectar y Tratar Outliers\") # Botón para detectar y tratar outliers.\n",
        "        msg_resultado_outliers = gr.Textbox(label=\"Resultado Outliers\") # Muestra el resultado del tratamiento de outliers.\n",
        "\n",
        "    # Define la tercera pestaña para análisis y visualización.\n",
        "    with gr.Tab(\"3. Análisis y Visualización\"):\n",
        "        gr.Markdown(\"### Análisis Estadístico (Correlación, Curtosis y Asimetría) [25]\") # Subtítulo.\n",
        "\n",
        "        output_analisis = gr.Markdown(label=\"Resumen Estadístico e Interpretación\") # Muestra el resumen estadístico.\n",
        "        btn_ejecutar_analisis = gr.Button(\"Ejecutar Análisis Estadístico\") # Botón para ejecutar el análisis.\n",
        "\n",
        "        gr.Markdown(\"### Visualización de Datos Procesados [25]\") # Subtítulo.\n",
        "        with gr.Row(): # Organiza los componentes en una fila.\n",
        "            # Dropdown para seleccionar una columna numérica para el gráfico de distribución.\n",
        "            input_col_distribucion = gr.Dropdown(label=\"Columna para Gráfico de Distribución (Histograma/Boxplot)\", choices=[], interactive=True)\n",
        "\n",
        "        btn_generar_graficos = gr.Button(\"Generar Gráficos\") # Botón para generar los gráficos.\n",
        "\n",
        "        with gr.Row(): # Muestra los gráficos generados en una fila.\n",
        "            plot_correlacion = gr.Plot(label=\"Mapa de Calor de Correlaciones\") # Muestra el mapa de calor.\n",
        "            plot_distribucion = gr.Plot(label=\"Distribución y Outliers (Boxplot/Histograma)\") # Muestra el gráfico de distribución.\n",
        "        msg_graficos = gr.Textbox(label=\"Mensaje de Gráficos\") # Muestra mensajes de estado de los gráficos.\n",
        "\n",
        "    # Define la cuarta pestaña para exportación y reporte.\n",
        "    with gr.Tab(\"4. Exportación y Reporte\"):\n",
        "        gr.Markdown(\"### Exportar Datos Procesados y Generar Log [36]\") # Subtítulo.\n",
        "\n",
        "        radio_formato_exportacion = gr.Radio(\n",
        "            choices=[\"CSV\", \"Excel\"],\n",
        "            label=\"Seleccionar Formato de Exportación\",\n",
        "            value=\"CSV\"\n",
        "        )\n",
        "\n",
        "        btn_generar_archivos = gr.Button(\"Generar Archivos Finales\") # Botón para generar los archivos de salida.\n",
        "        msg_exportacion = gr.Textbox(label=\"Resultado de la Exportación\") # Muestra el resultado de la exportación.\n",
        "\n",
        "        output_archivo_datos = gr.File(label=\"Descargar Datos Procesados\") # Componente para descargar el DataFrame procesado.\n",
        "        output_archivo_log = gr.File(label=\"Descargar Reporte de Log\") # Componente para descargar el reporte de log.\n",
        "\n",
        "    # Definición de las interacciones entre los componentes de Gradio y las funciones Python.\n",
        "\n",
        "    # Al hacer clic en 'Cargar y Validar', se ejecuta 'cargar_datos'.\n",
        "    btn_cargar_datos.click(\n",
        "        fn=cargar_datos,\n",
        "        inputs=[input_archivo, radio_separador],\n",
        "        outputs=[estado_df_gradio, msg_carga_datos, df_vista_previa]\n",
        "    ).success( # Después de una carga exitosa, actualiza las opciones del dropdown de columnas.\n",
        "        fn=update_dropdown_choices,\n",
        "        inputs=[estado_df_gradio],\n",
        "        outputs=[input_col_distribucion]\n",
        "    )\n",
        "\n",
        "    # Al hacer clic en 'Aplicar Limpieza de Nulos', se ejecuta 'manejar_valores_nulos'.\n",
        "    btn_aplicar_nulos.click(\n",
        "        fn=manejar_valores_nulos,\n",
        "        inputs=[estado_df_gradio, input_col_nulos, radio_metodo_nulos],\n",
        "        outputs=[estado_df_gradio, msg_resultado_nulos, df_vista_previa]\n",
        "    ).success( # Después de la limpieza, actualiza el dropdown de columnas.\n",
        "        fn=update_dropdown_choices,\n",
        "        inputs=[estado_df_gradio],\n",
        "        outputs=[input_col_distribucion]\n",
        "    )\n",
        "\n",
        "    # Al hacer clic en 'Aplicar Normalización / Estandarización', se ejecuta 'aplicar_escalado'.\n",
        "    btn_aplicar_escalado.click(\n",
        "        fn=aplicar_escalado,\n",
        "        inputs=[estado_df_gradio, input_col_escalar, radio_metodo_escalado],\n",
        "        outputs=[estado_df_gradio, msg_resultado_escalado, df_vista_previa]\n",
        "    ).success( # Después del escalado, actualiza el dropdown de columnas.\n",
        "        fn=update_dropdown_choices,\n",
        "        inputs=[estado_df_gradio],\n",
        "        outputs=[input_col_distribucion]\n",
        "    )\n",
        "\n",
        "    # Al hacer clic en 'Detectar y Tratar Outliers', se ejecuta 'detectar_y_tratar_outliers'.\n",
        "    btn_detectar_outliers.click(\n",
        "        fn=detectar_y_tratar_outliers,\n",
        "        inputs=[estado_df_gradio, input_col_outliers, radio_tratamiento_outliers],\n",
        "        outputs=[estado_df_gradio, msg_resultado_outliers, df_vista_previa]\n",
        "    ).success( # Después del tratamiento de outliers, actualiza el dropdown de columnas.\n",
        "        fn=update_dropdown_choices,\n",
        "        inputs=[estado_df_gradio],\n",
        "        outputs=[input_col_distribucion]\n",
        "    )\n",
        "\n",
        "    # Al hacer clic en 'Ejecutar Análisis Estadístico', se ejecuta 'ejecutar_analisis'.\n",
        "    btn_ejecutar_analisis.click(\n",
        "        fn=ejecutar_analisis,\n",
        "        inputs=[estado_df_gradio],\n",
        "        outputs=[output_analisis, gr.State(None)] # El segundo output es un estado que no se muestra, puede ser para la matriz de correlación interna.\n",
        "    )\n",
        "\n",
        "    # Al hacer clic en 'Generar Gráficos', se ejecuta 'generar_graficos'.\n",
        "    btn_generar_graficos.click(\n",
        "        fn=generar_graficos,\n",
        "        inputs=[estado_df_gradio, gr.State(None), input_col_distribucion],\n",
        "        outputs=[plot_correlacion, plot_distribucion, msg_graficos]\n",
        "    )\n",
        "\n",
        "    # Al hacer clic en 'Generar Archivos Finales', se ejecuta 'exportar_resultados'.\n",
        "    btn_generar_archivos.click(\n",
        "        fn=exportar_resultados,\n",
        "        inputs=[estado_df_gradio, radio_formato_exportacion],\n",
        "        outputs=[msg_exportacion, output_archivo_datos, output_archivo_log]\n",
        "    )"
      ],
      "metadata": {
        "id": "ggoZZRhg1dPe"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicia la interfaz Gradio si el script se ejecuta directamente.\n",
        "if __name__ == \"__main__\": # Asegura que el código se ejecuta solo cuando el script es el programa principal.\n",
        "    interfaz.launch(inline=True) # Lanza la interfaz de Gradio, incrustándola en la salida de la celda de Colab."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "outputId": "786e5085-4c16-4913-daa9-088f0010913e",
        "id": "OJrbjig4DpXc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6b582462a301b36f15.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6b582462a301b36f15.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}