{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOsGfkFPOj5yspggzLDJG19",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Medalcode/Colab1/blob/main/Eval3Mineria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "aqui instalamos y cargamos las librer√≠as\n",
        "\n",
        "tidyverse (importaci√≥n, manipulaci√≥n, visualizaci√≥n y an√°lisis de datos)\n",
        "\n",
        "readxl (facilita la extracci√≥n de datos de Excel a R)\n",
        "\n",
        "pandas\n"
      ],
      "metadata": {
        "id": "a6k05rvDo9uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pds  #entonces pds es pandas\n",
        "import numpy as npy   #el apodo de numpy es npy\n",
        "import io             #la libreria io permite trabajar con flujos de entrada y salida de datos\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gradio as gr\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from scipy.stats import skew, kurtosis\n",
        "import os\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "q_5cQARUqjj5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuraci√≥n inicial para Matplotlib/Seaborn\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Variable global para almacenar el DataFrame y el historial de operaciones (Log)\n",
        "# Esto simula gr.State() para mantener el estado entre las llamadas a las funciones.\n",
        "df_state = None\n",
        "log_entries = []"
      ],
      "metadata": {
        "id": "J_VE2ELBUj2_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_obj, delimiter_choice):\n",
        "    \"\"\"I.1 load_data: Carga el archivo subido en un DataFrame.\"\"\"\n",
        "    global df_state, log_entries\n",
        "    log_entries = []\n",
        "\n",
        "    if file_obj is None:\n",
        "        return None, \"Error: Debe subir un archivo.\", None\n",
        "\n",
        "    file_path = file_obj.name\n",
        "\n",
        "    try:\n",
        "        if file_path.endswith('.csv'):\n",
        "            if delimiter_choice == \"Comma (,)\":\n",
        "                delimiter = ','\n",
        "            elif delimiter_choice == \"Semicolon (;)\":\n",
        "                delimiter = ';'\n",
        "            else:\n",
        "                delimiter = ',' # Default fallback\n",
        "\n",
        "            # Intentar leer el archivo con codificaciones comunes [7]\n",
        "            try:\n",
        "                df = pd.read_csv(file_path, delimiter=delimiter, encoding='utf-8')\n",
        "            except UnicodeDecodeError:\n",
        "                df = pd.read_csv(file_path, delimiter=delimiter, encoding='ISO-8859-1')\n",
        "\n",
        "        elif file_path.endswith(('.xls', '.xlsx')):\n",
        "            df = pd.read_excel(file_path) # Requiere openpyxl [4]\n",
        "\n",
        "        else:\n",
        "            return None, \"Error: Archivo no v√°lido. Suba un archivo CSV o Excel.\", None\n",
        "\n",
        "        # Validaci√≥n de tipos de datos (debe contener categ√≥ricos y num√©ricos) [6]\n",
        "        num_cols = df.select_dtypes(include=np.number).columns\n",
        "        cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "        if len(num_cols) == 0 or len(cat_cols) == 0:\n",
        "            msg = \"Advertencia: El archivo debe contener tanto datos categ√≥ricos como num√©ricos para un an√°lisis completo.\"\n",
        "        else:\n",
        "            msg = f\"Archivo cargado. Dimensiones: {df.shape}. {len(num_cols)} num√©ricas, {len(cat_cols)} categ√≥ricas.\"\n",
        "\n",
        "        df_state = df\n",
        "        log_entries.append(f\"Carga: Archivo {os.path.basename(file_path)} cargado. Se detectaron {df.shape} filas.\")\n",
        "\n",
        "        # Retorna el DataFrame, el mensaje y una vista previa [8]\n",
        "        return df_state, msg, gr.Dataframe(value=df.head())\n",
        "\n",
        "    except Exception as e:\n",
        "        df_state = None\n",
        "        return None, f\"Error de lectura: {str(e)}\", None"
      ],
      "metadata": {
        "id": "xNehtvl3YtfT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_numeric_cols(df):\n",
        "    \"\"\"Funci√≥n auxiliar para obtener columnas num√©ricas.\"\"\"\n",
        "    return df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "def handle_missing_values(df_in, col_name, method):\n",
        "    \"\"\"II.1 handle_missing_values: Manejo interactivo de valores nulos.\"\"\"\n",
        "    global df_state, log_entries\n",
        "    df = df_in.copy()\n",
        "\n",
        "    # Manejar el caso donde no hay DF cargado\n",
        "    if df is None:\n",
        "        return None, \"Error: Primero cargue un archivo.\", None\n",
        "\n",
        "    col_names = [c.strip() for c in col_name.split(\",\") if c.strip()]\n",
        "\n",
        "    # Contar nulos antes de la operaci√≥n [9]\n",
        "    total_nulos_antes = df[col_names].isnull().sum().sum()\n",
        "    registros_afectados = 0\n",
        "\n",
        "    if total_nulos_antes == 0:\n",
        "        msg = \"No se encontraron valores nulos en las columnas seleccionadas. No se realiz√≥ ninguna operaci√≥n.\"\n",
        "        return df_state, msg, None\n",
        "\n",
        "    if method == \"Eliminar filas\":\n",
        "        filas_originales = len(df)\n",
        "        df = df.dropna(subset=col_names)\n",
        "        registros_afectados = filas_originales - len(df)\n",
        "        log_entries.append(f\"Limpieza Nulos: Se eliminaron {registros_afectados} filas con nulos en {', '.join(col_names)}.\")\n",
        "\n",
        "    else: # M√©todos de imputaci√≥n (promedio, m√°ximo, m√≠nimo, cero)\n",
        "        for col in col_names:\n",
        "            if col not in df.columns or col not in get_numeric_cols(df):\n",
        "                log_entries.append(f\"Advertencia: La columna '{col}' no es num√©rica o no existe para imputaci√≥n.\")\n",
        "                continue\n",
        "\n",
        "            if method == \"Llenar con promedio\":\n",
        "                valor = df[col].mean()\n",
        "            elif method == \"Llenar con m√°ximo\":\n",
        "                valor = df[col].max()\n",
        "            elif method == \"Llenar con m√≠nimo\":\n",
        "                valor = df[col].min()\n",
        "            elif method == \"Llenar con cero\":\n",
        "                valor = 0\n",
        "\n",
        "            df[col] = df[col].fillna(valor)\n",
        "            registros_afectados += df[col].isnull().sum() # Sumar√° 0 si la imputaci√≥n fue exitosa\n",
        "            log_entries.append(f\"Limpieza Nulos: La columna '{col}' se imput√≥ con {method.split(' ')[-1]} ({valor:.2f}).\")\n",
        "\n",
        "    df_state = df # Actualizar el estado global\n",
        "    msg = f\"Limpieza completada. {total_nulos_antes} valores nulos tratados. Registros afectados: {registros_afectados}.\"\n",
        "    return df_state, msg, gr.Dataframe(value=df_state.head())\n",
        "\n",
        "\n",
        "def apply_scaling(df_in, col_name, method):\n",
        "    \"\"\"II.2 apply_scaling: Aplica normalizaci√≥n o estandarizaci√≥n.\"\"\"\n",
        "    global df_state, log_entries\n",
        "    df = df_in.copy()\n",
        "\n",
        "    if df is None:\n",
        "        return None, \"Error: Primero cargue un archivo.\", None\n",
        "\n",
        "    col_names = [c.strip() for c in col_name.split(\",\") if c.strip()]\n",
        "    if not all(col in df.columns and col in get_numeric_cols(df) for col in col_names):\n",
        "        return df_state, \"Error: Verifique que las columnas existan y sean num√©ricas.\", None\n",
        "\n",
        "    if method == \"Min-Max\":\n",
        "        scaler = MinMaxScaler()\n",
        "        justificacion = \"**Recomendaci√≥n Min-Max:** Se recomienda para algoritmos que esperan un rango acotado (ej. Redes Neuronales) o cuando la distribuci√≥n no es gaussiana. Sin embargo, es sensible a los *outliers* [10-12].\"\n",
        "    elif method == \"Z-Score\":\n",
        "        scaler = StandardScaler()\n",
        "        justificacion = \"**Recomendaci√≥n Z-Score:** Se recomienda para algoritmos basados en distancias (ej. K-Means, KNN) o cuando se asume una distribuci√≥n aproximadamente normal. Es menos sensible a los *outliers* que Min-Max [10, 12, 13].\"\n",
        "    else:\n",
        "        return df_state, \"M√©todo de escalado no v√°lido.\", None\n",
        "\n",
        "    for col in col_names:\n",
        "        df[col] = scaler.fit_transform(df[[col]])\n",
        "        log_entries.append(f\"Escalado: Columna '{col}' escalada usando {method}.\")\n",
        "\n",
        "    df_state = df\n",
        "    msg = f\"Escalado de {', '.join(col_names)} completado usando {method}. {justificacion}\"\n",
        "    return df_state, msg, gr.Dataframe(value=df_state.head())\n",
        "\n",
        "\n",
        "def detect_and_treat_outliers(df_in, col_name, treatment):\n",
        "    \"\"\"II.3 detect_and_treat_outliers: Detecci√≥n por IQR y tratamiento.\"\"\"\n",
        "    global df_state, log_entries\n",
        "    df = df_in.copy()\n",
        "\n",
        "    if df is None:\n",
        "        return None, \"Error: Primero cargue un archivo.\", None\n",
        "\n",
        "    if col_name not in df.columns or col_name not in get_numeric_cols(df):\n",
        "        return df_state, f\"Error: La columna '{col_name}' no existe o no es num√©rica.\", None\n",
        "\n",
        "    # Detecci√≥n por IQR [10, 14-17]\n",
        "    Q1 = df[col_name].quantile(0.25)\n",
        "    Q3 = df[col_name].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    limite_inferior = Q1 - 1.5 * IQR\n",
        "    limite_superior = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers_detectados = df[(df[col_name] < limite_inferior) | (df[col_name] > limite_superior)]\n",
        "    n_outliers = len(outliers_detectados)\n",
        "\n",
        "    if n_outliers == 0:\n",
        "        msg = f\"No se detectaron *outliers* en la columna '{col_name}' (M√©todo IQR).\"\n",
        "        return df_state, msg, None\n",
        "\n",
        "    # Tratamiento [10, 18-20]\n",
        "    if treatment == \"Eliminar registros\":\n",
        "        df = df[~((df[col_name] < limite_inferior) | (df[col_name] > limite_superior))]\n",
        "        log_entries.append(f\"Outliers: Se eliminaron {n_outliers} *outliers* en '{col_name}'.\")\n",
        "        msg = f\"Se detectaron y eliminaron {n_outliers} *outliers* en '{col_name}'. Se eliminaron {n_outliers} filas.\"\n",
        "\n",
        "    elif treatment == \"Capping (Winsorizaci√≥n)\":\n",
        "        # Limitar valores extremos al l√≠mite inferior y superior del bigote [19]\n",
        "        df[col_name] = np.where(df[col_name] > limite_superior, limite_superior, df[col_name])\n",
        "        df[col_name] = np.where(df[col_name] < limite_inferior, limite_inferior, df[col_name])\n",
        "        log_entries.append(f\"Outliers: Se aplic√≥ *capping* a {n_outliers} *outliers* en '{col_name}'.\")\n",
        "        msg = f\"Se detectaron {n_outliers} *outliers* y se aplic√≥ *Capping* (Winsorizaci√≥n) para conservar los registros.\"\n",
        "\n",
        "    else:\n",
        "        msg = f\"Se detectaron {n_outliers} *outliers* en '{col_name}'. Se recomienda tratarlos, ya que pueden sesgar la media y la desviaci√≥n est√°ndar [15, 21].\"\n",
        "        df_state = df_in\n",
        "        return df_state, msg, None\n",
        "\n",
        "    df_state = df\n",
        "    return df_state, msg, gr.Dataframe(value=df_state.head())"
      ],
      "metadata": {
        "id": "YUDj1a_4Y0qS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_analysis(df_in):\n",
        "    \"\"\"III.1 run_analysis: Calcula estad√≠sticas descriptivas, correlaci√≥n, curtosis y asimetr√≠a.\"\"\"\n",
        "    if df_in is None:\n",
        "        return \"Error: Primero cargue y procese el archivo.\", None\n",
        "\n",
        "    df_num = df_in.select_dtypes(include=np.number)\n",
        "\n",
        "    if df_num.empty:\n",
        "        return \"El DataFrame no contiene columnas num√©ricas para el an√°lisis estad√≠stico.\", None\n",
        "\n",
        "    # 1. Estad√≠sticas Descriptivas [25-27]\n",
        "    estadisticas = df_num.describe().T\n",
        "\n",
        "    # 2. Correlaciones [25, 27]\n",
        "    correlaciones = df_num.corr(method='pearson') # Pearson para relaci√≥n lineal [28]\n",
        "\n",
        "    # 3. Curtosis y Asimetr√≠a (Skewness) [25, 27, 29, 30]\n",
        "    curtosis_series = df_num.apply(kurtosis, fisher=False) # Fisher=False para valor absoluto (Normal=3)\n",
        "    asimetria_series = df_num.apply(skew)\n",
        "\n",
        "    resumen_forma = pd.DataFrame({\n",
        "        'Curtosis (Normal ‚âà 3)': curtosis_series,\n",
        "        'Asimetr√≠a (Skewness)': asimetria_series\n",
        "    }).round(3)\n",
        "\n",
        "    # Interpretaci√≥n de Resultados (Ejemplo)\n",
        "    interpretacion = \"### Resumen de Interpretaci√≥n:\\n\"\n",
        "    interpretacion += \"- **Curtosis:** Los valores > 3 (Leptoc√∫rtica) indican un pico m√°s agudo y colas pesadas, sugiriendo m√°s *outliers* [30].\\n\"\n",
        "    interpretacion += \"- **Asimetr√≠a:** Valores positivos (> 0) indican sesgo a la derecha (media > mediana) [29, 31].\\n\"\n",
        "    interpretacion += \"- **Correlaci√≥n:** Los valores cercanos a 1 o -1 en el mapa de calor indican relaciones lineales fuertes entre pares de variables [32].\\n\"\n",
        "\n",
        "    log_entries.append(\"An√°lisis Estad√≠stico: C√°lculos descriptivos, curtosis y asimetr√≠a generados.\")\n",
        "\n",
        "    # Formatear el resultado en un solo string\n",
        "    resultado_texto = (\n",
        "        f\"{interpretacion}\\n\\n\"\n",
        "        f\"**Estad√≠sticas Descriptivas (Media, Desviaci√≥n, Cuartiles):**\\n{estadisticas.to_markdown()}\\n\\n\"\n",
        "        f\"**Forma de la Distribuci√≥n (Curtosis y Asimetr√≠a):**\\n{resumen_forma.to_markdown()}\\n\"\n",
        "    )\n",
        "\n",
        "    return resultado_texto, correlaciones\n",
        "\n",
        "\n",
        "def generate_plots(df_in, col_corr, col_dist):\n",
        "    \"\"\"III.2 generate_plots: Genera un mapa de calor y un histograma/boxplot.\"\"\"\n",
        "    if df_in is None:\n",
        "        return None, \"Error: Primero cargue el archivo.\", None\n",
        "\n",
        "    df_num = df_in.select_dtypes(include=np.number)\n",
        "\n",
        "    # Gr√°fico 1: Mapa de Correlaci√≥n (Heatmap) [25, 27, 33]\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(df_num.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "    plt.title(\"Mapa de Calor de Correlaciones (Pearson)\")\n",
        "    correlation_plot_path = \"correlation_plot.png\"\n",
        "    plt.savefig(correlation_plot_path)\n",
        "    plt.close()\n",
        "\n",
        "    # Gr√°fico 2: Distribuci√≥n (Histograma + Boxplot) [25, 26]\n",
        "    if col_dist in df_num.columns:\n",
        "        fig, axes = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
        "\n",
        "        # Histograma (Distribuci√≥n) [34]\n",
        "        sns.histplot(df_num[col_dist], kde=True, ax=axes)\n",
        "        axes.set_title(f\"Distribuci√≥n de: {col_dist} (Histograma y KDE)\")\n",
        "\n",
        "        # Boxplot (Detecci√≥n de Outliers) [15, 26]\n",
        "        sns.boxplot(x=df_num[col_dist], ax=axes[35])\n",
        "        axes[35].set_title(f\"Boxplot de: {col_dist} (Outliers: 1.5*IQR)\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        distribution_plot_path = \"distribution_plot.png\"\n",
        "        plt.savefig(distribution_plot_path)\n",
        "        plt.close()\n",
        "    else:\n",
        "        distribution_plot_path = None\n",
        "        log_entries.append(\"Advertencia: No se pudo generar el gr√°fico de distribuci√≥n, columna no num√©rica o inexistente.\")\n",
        "\n",
        "    log_entries.append(\"Visualizaci√≥n: Gr√°ficos de correlaci√≥n y distribuci√≥n generados.\")\n",
        "    return correlation_plot_path, distribution_plot_path\n",
        "\n",
        "\n",
        "def export_results(df_in, export_format):\n",
        "    \"\"\"IV.1 export_results: Permite la exportaci√≥n y genera el reporte de log.\"\"\"\n",
        "    global log_entries\n",
        "\n",
        "    if df_in is None:\n",
        "        return \"Error: No hay datos procesados para exportar.\", None, None\n",
        "\n",
        "    # --- 1. Generar el reporte breve autom√°tico (Log) [24, 36, 37]\n",
        "    reporte_path = \"reporte_analisis.txt\"\n",
        "    log_content = \"\\n\".join(log_entries)\n",
        "\n",
        "    # Incluir el reporte descriptivo de la actividad [37]\n",
        "    reporte_final = (\n",
        "        \"### REPORTE BREVE AUTOM√ÅTICO DE PROCESAMIENTO DE DATOS\\n\\n\"\n",
        "        \"**Proceso Seguido y Decisiones Tomadas en Limpieza de Datos:**\\n\"\n",
        "        f\"{log_content}\\n\\n\"\n",
        "        f\"**Interpretaci√≥n Preliminar de Resultados Obtenidos:**\\n\"\n",
        "        f\"(La interpretaci√≥n completa de correlaciones, curtosis y regresiones debe realizarla el analista.)\\n\"\n",
        "        f\"Se recomienda revisar el *heatmap* para correlaciones fuertes (Pearson > 0.7 o < -0.7) [32, 38].\\n\"\n",
        "        f\"La limpieza de datos asegura la calidad y reduce el sesgo en fases de modelado posteriores (GIGO: *Garbage In, Garbage Out*) [39].\\n\"\n",
        "        f\"Dimensiones del DataFrame final: {df_in.shape}\\n\"\n",
        "    )\n",
        "\n",
        "    with open(reporte_path, \"w\") as f:\n",
        "        f.write(reporte_final)\n",
        "\n",
        "    # --- 2. Exportaci√≥n de datos procesados [24, 27, 36]\n",
        "    if export_format == \"CSV\":\n",
        "        salida_path = \"datos_procesados.csv\"\n",
        "        df_in.to_csv(salida_path, index=False)\n",
        "    elif export_format == \"Excel\":\n",
        "        salida_path = \"datos_procesados.xlsx\"\n",
        "        df_in.to_excel(salida_path, index=False)\n",
        "    else:\n",
        "        return \"Error: Formato de exportaci√≥n no v√°lido.\", None, None\n",
        "\n",
        "    log_entries.append(f\"Exportaci√≥n: Datos procesados guardados en {salida_path} y Log generado.\")\n",
        "\n",
        "    return f\"Exportaci√≥n exitosa. Descargue el archivo y el reporte.\", salida_path, reporte_path"
      ],
      "metadata": {
        "id": "AUYCcG8VZAT5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapear las funciones para Gradio\n",
        "# Usaremos un gr.State para manejar el DataFrame a lo largo de las funciones.\n",
        "\n",
        "def get_col_names(df_state):\n",
        "    \"\"\"Funci√≥n que devuelve nombres de columnas num√©ricas para los Dropdowns.\"\"\"\n",
        "    if df_state is not None:\n",
        "        # Devuelve las columnas num√©ricas para las opciones de escalado/outliers\n",
        "        return df_state.select_dtypes(include=np.number).columns.tolist()\n",
        "    return []\n",
        "\n",
        "# ----------------- Estructura de la Interfaz -----------------\n",
        "\n",
        "with gr.Blocks(title=\"Aplicaci√≥n de Miner√≠a de Datos y EDA\") as interfaz:\n",
        "    gr.Markdown(\"## üõ†Ô∏è Aplicaci√≥n Interactiva para Procesamiento y An√°lisis de Datos\")\n",
        "\n",
        "    # Estado para mantener el DataFrame entre llamadas\n",
        "    df_state_var = gr.State(None)\n",
        "\n",
        "    with gr.Tab(\"1. Carga de Datos\"):\n",
        "        gr.Markdown(\"### Carga y Validaci√≥n del Archivo\")\n",
        "        with gr.Row():\n",
        "            separador = gr.Radio(\n",
        "                choices=[\"Comma (,)\", \"Semicolon (;)\"],\n",
        "                label=\"Selecciona el Separador del Archivo\",\n",
        "                value=\"Comma (,)\",\n",
        "                interactive=True\n",
        "            )\n",
        "            archivo = gr.File(label=\"Subir Archivo (CSV o Excel)\", interactive=True)\n",
        "\n",
        "        btn_cargar = gr.Button(\"Cargar y Validar\")\n",
        "        msg_carga = gr.Textbox(label=\"Mensaje de Carga\")\n",
        "        df_preview = gr.Dataframe(label=\"Vista Previa (5 primeras filas)\")\n",
        "\n",
        "        # Enlace de carga\n",
        "        btn_cargar.click(\n",
        "            fn=load_data,\n",
        "            inputs=[archivo, separador],\n",
        "            outputs=[df_state_var, msg_carga, df_preview]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"2. Procesamiento y Limpieza (Data Preparation)\"):\n",
        "        gr.Markdown(\"### Limpieza de Valores Nulos\")\n",
        "        with gr.Row():\n",
        "            metodo_nulos = gr.Radio(\n",
        "                choices=[\"Eliminar filas\", \"Llenar con promedio\", \"Llenar con m√°ximo\", \"Llenar con m√≠nimo\", \"Llenar con cero\"],\n",
        "                label=\"M√©todo para manejar nulos [6, 41]\",\n",
        "                value=\"Eliminar filas\"\n",
        "            )\n",
        "            col_nulos = gr.Textbox(label=\"Columnas para Limpieza (Separadas por comas)\", placeholder=\"Ej: Col1, Col2 (Dejar vac√≠o para todo el DF)\")\n",
        "\n",
        "        btn_nulos = gr.Button(\"Aplicar Limpieza de Nulos\")\n",
        "        msg_nulos = gr.Textbox(label=\"Resultado Nulos\")\n",
        "\n",
        "        gr.Markdown(\"### Normalizaci√≥n y Estandarizaci√≥n\")\n",
        "        with gr.Row():\n",
        "            metodo_normalizacion = gr.Radio(\n",
        "                choices=[\"Min-Max\", \"Z-Score\"],\n",
        "                label=\"M√©todo de Escalado [10, 42]\",\n",
        "                value=\"Z-Score\"\n",
        "            )\n",
        "            col_normalizar = gr.Textbox(label=\"Columnas Num√©ricas para Escalar (Separadas por comas)\")\n",
        "\n",
        "        btn_normalizar = gr.Button(\"Aplicar Normalizaci√≥n / Estandarizaci√≥n\")\n",
        "        msg_normalizar = gr.Textbox(label=\"Resultado Normalizaci√≥n y Justificaci√≥n [10]\")\n",
        "\n",
        "        gr.Markdown(\"### Detecci√≥n y Tratamiento de Outliers (IQR)\")\n",
        "        with gr.Row():\n",
        "            col_outliers = gr.Textbox(label=\"Columna para Detecci√≥n de Outliers (Una sola columna)\")\n",
        "            tratamiento_outliers = gr.Radio(\n",
        "                choices=[\"Informar\", \"Eliminar registros\", \"Capping (Winsorizaci√≥n)\"],\n",
        "                label=\"Tratamiento de Outliers [10, 19, 20]\",\n",
        "                value=\"Informar\"\n",
        "            )\n",
        "\n",
        "        btn_outliers = gr.Button(\"Detectar y Tratar Outliers\")\n",
        "        msg_outliers = gr.Textbox(label=\"Resultado Outliers\")\n",
        "\n",
        "        # Enlaces de procesamiento\n",
        "        btn_nulos.click(\n",
        "            fn=handle_missing_values,\n",
        "            inputs=[df_state_var, col_nulos, metodo_nulos],\n",
        "            outputs=[df_state_var, msg_nulos, df_preview]\n",
        "        )\n",
        "        btn_normalizar.click(\n",
        "            fn=apply_scaling,\n",
        "            inputs=[df_state_var, col_normalizar, metodo_normalizacion],\n",
        "            outputs=[df_state_var, msg_normalizar, df_preview]\n",
        "        )\n",
        "        btn_outliers.click(\n",
        "            fn=detect_and_treat_outliers,\n",
        "            inputs=[df_state_var, col_outliers, tratamiento_outliers],\n",
        "            outputs=[df_state_var, msg_outliers, df_preview]\n",
        "        )\n",
        "\n",
        "\n",
        "    with gr.Tab(\"3. An√°lisis y Visualizaci√≥n\"):\n",
        "        gr.Markdown(\"### An√°lisis Estad√≠stico (Correlaci√≥n, Curtosis y Asimetr√≠a) [25]\")\n",
        "\n",
        "        btn_analisis = gr.Button(\"Ejecutar An√°lisis Estad√≠stico\")\n",
        "        analisis_output = gr.Markdown(label=\"Resumen Estad√≠stico e Interpretaci√≥n\")\n",
        "\n",
        "        gr.Markdown(\"### Visualizaci√≥n de Datos Procesados [25]\")\n",
        "        with gr.Row():\n",
        "            col_distribucion = gr.Textbox(label=\"Columna para Gr√°fico de Distribuci√≥n (Histograma/Boxplot)\")\n",
        "\n",
        "        btn_graficos = gr.Button(\"Generar Gr√°ficos\")\n",
        "\n",
        "        with gr.Row():\n",
        "            plot_corr = gr.Plot(label=\"Mapa de Calor de Correlaciones\")\n",
        "            plot_dist = gr.Plot(label=\"Distribuci√≥n y Outliers (Boxplot/Histograma)\")\n",
        "\n",
        "        # Enlaces de an√°lisis\n",
        "        btn_analisis.click(\n",
        "            fn=run_analysis,\n",
        "            inputs=[df_state_var],\n",
        "            outputs=[analisis_output, gr.State(None)] # El segundo output no es usado pero necesario para que el DF se mantenga en el estado\n",
        "        )\n",
        "        btn_graficos.click(\n",
        "            fn=generate_plots,\n",
        "            inputs=[df_state_var, gr.State(None), col_distribucion],\n",
        "            outputs=[plot_corr, plot_dist]\n",
        "        )\n",
        "\n",
        "\n",
        "    with gr.Tab(\"4. Exportaci√≥n y Reporte\"):\n",
        "        gr.Markdown(\"### Exportar Datos Procesados y Generar Log [36]\")\n",
        "\n",
        "        export_format = gr.Radio(\n",
        "            choices=[\"CSV\", \"Excel\"],\n",
        "            label=\"Seleccionar Formato de Exportaci√≥n\",\n",
        "            value=\"CSV\"\n",
        "        )\n",
        "\n",
        "        btn_exportar = gr.Button(\"Generar Archivos Finales\")\n",
        "        msg_export = gr.Textbox(label=\"Resultado de la Exportaci√≥n\")\n",
        "\n",
        "        # Los archivos de descarga deben ser componentes File [43]\n",
        "        file_output = gr.File(label=\"Descargar Datos Procesados\")\n",
        "        log_output = gr.File(label=\"Descargar Reporte de Log\")\n",
        "\n",
        "        # Enlace de exportaci√≥n\n",
        "        btn_exportar.click(\n",
        "            fn=export_results,\n",
        "            inputs=[df_state_var, export_format],\n",
        "            outputs=[msg_export, file_output, log_output]\n",
        "        )\n",
        "\n",
        "\n",
        "# Iniciar la interfaz\n",
        "if __name__ == \"__main__\":\n",
        "    interfaz.launch(inline=True)"
      ],
      "metadata": {
        "id": "hZqWlggkZILm",
        "outputId": "661ca7d6-ee16-423a-e4ab-4c75cf526b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6e7c56c3538dfeb72d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6e7c56c3538dfeb72d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}