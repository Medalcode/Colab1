{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOpj9yLJhhC4PTPhR3Q8HSu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Medalcode/Colab1/blob/main/Eval3Mineria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gradio as gr\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from scipy.stats import skew, kurtosis\n",
        "import os\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "kvholmIzygiE"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuraci√≥n inicial para Matplotlib/Seaborn\n",
        "sns.set_theme(style=\"whitegrid\")\n"
      ],
      "metadata": {
        "id": "WlHdnscqyqOW"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Variables globales para almacenar el DataFrame y el historial de operaciones (Log)\n",
        "estado_df = None\n",
        "entradas_log = []"
      ],
      "metadata": {
        "id": "FgL05IKHyjdk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_columnas_numericas(df_entrada):\n",
        "    \"\"\"Funci√≥n auxiliar para obtener columnas num√©ricas.\"\"\"\n",
        "    if df_entrada is not None:\n",
        "        return df_entrada.select_dtypes(include=np.number).columns.tolist()\n",
        "    return []\n"
      ],
      "metadata": {
        "id": "ftLC_yuEyzXA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cargar_datos(archivo_obj, delimitador_elegido):\n",
        "    \"\"\"I.1 cargar_datos: Carga el archivo subido en un DataFrame.\"\"\"\n",
        "    global estado_df, entradas_log\n",
        "    entradas_log = [] # Reiniciar el log en cada nueva carga\n",
        "\n",
        "    if archivo_obj is None:\n",
        "        return None, \"Error: Debe subir un archivo.\", None\n",
        "\n",
        "    ruta_archivo = archivo_obj.name\n",
        "\n",
        "    try:\n",
        "        if ruta_archivo.endswith('.csv'):\n",
        "            if delimitador_elegido == \"Coma (,)\":\n",
        "                delimitador = ','\n",
        "            elif delimitador_elegido == \"Punto y Coma (;)\":\n",
        "                delimitador = ';'\n",
        "            else:\n",
        "                delimitador = ',' # Delimitador por defecto\n",
        "\n",
        "            # Intentar leer el archivo con codificaciones comunes\n",
        "            try:\n",
        "                df_datos = pd.read_csv(ruta_archivo, delimiter=delimitador, encoding='utf-8')\n",
        "            except UnicodeDecodeError:\n",
        "                df_datos = pd.read_csv(ruta_archivo, delimiter=delimitador, encoding='ISO-8859-1')\n",
        "\n",
        "        elif ruta_archivo.endswith(('.xls', '.xlsx')):\n",
        "            df_datos = pd.read_excel(ruta_archivo)\n",
        "\n",
        "        else:\n",
        "            return None, \"Error: Archivo no v√°lido. Suba un archivo CSV o Excel.\", None\n",
        "\n",
        "        # Validaci√≥n de tipos de datos (debe contener categ√≥ricos y num√©ricos)\n",
        "        columnas_numericas = df_datos.select_dtypes(include=np.number).columns\n",
        "        columnas_categoricas = df_datos.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "        if len(columnas_numericas) == 0 or len(columnas_categoricas) == 0:\n",
        "            mensaje = \"Advertencia: El archivo debe contener tanto datos categ√≥ricos como num√©ricos para un an√°lisis completo.\"\n",
        "        else:\n",
        "            mensaje = f\"Archivo cargado. Dimensiones: {df_datos.shape}. {len(columnas_numericas)} num√©ricas, {len(columnas_categoricas)} categ√≥ricas.\"\n",
        "\n",
        "        estado_df = df_datos\n",
        "        entradas_log.append(f\"Carga: Archivo {os.path.basename(ruta_archivo)} cargado. Se detectaron {df_datos.shape[0]} filas.\")\n",
        "\n",
        "        # Retorna el DataFrame, el mensaje y una vista previa\n",
        "        return estado_df, mensaje, gr.Dataframe(value=df_datos.head())\n",
        "\n",
        "    except Exception as e:\n",
        "        estado_df = None\n",
        "        return None, f\"Error de lectura: {str(e)}\", None"
      ],
      "metadata": {
        "id": "3fcjDVKry3K3"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def manejar_valores_nulos(df_entrada, nombres_columnas_str, metodo):\n",
        "    \"\"\"II.1 manejar_valores_nulos: Manejo interactivo de valores nulos.\"\"\"\n",
        "    global estado_df, entradas_log\n",
        "    df_procesado = df_entrada.copy() if df_entrada is not None else None\n",
        "\n",
        "    if df_procesado is None:\n",
        "        return None, \"Error: Primero cargue un archivo.\", None\n",
        "\n",
        "    nombres_columnas = [c.strip() for c in nombres_columnas_str.split(\",\") if c.strip()]\n",
        "    if not nombres_columnas:\n",
        "        # Si el usuario no especific√≥ columnas, aplicar a todas las columnas num√©ricas\n",
        "        nombres_columnas = get_columnas_numericas(df_procesado)\n",
        "        if not nombres_columnas:\n",
        "            return estado_df, \"Advertencia: No hay columnas num√©ricas para aplicar la limpieza de nulos.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "\n",
        "    total_nulos_previos = df_procesado[nombres_columnas].isnull().sum().sum()\n",
        "    filas_afectadas = 0\n",
        "\n",
        "    if total_nulos_previos == 0:\n",
        "        mensaje = \"No se encontraron valores nulos en las columnas seleccionadas. No se realiz√≥ ninguna operaci√≥n.\"\n",
        "        return estado_df, mensaje, gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    if metodo == \"Eliminar filas\":\n",
        "        total_filas_originales = len(df_procesado)\n",
        "        df_procesado = df_procesado.dropna(subset=nombres_columnas)\n",
        "        filas_afectadas = total_filas_originales - len(df_procesado)\n",
        "        entradas_log.append(f\"Limpieza Nulos: Se eliminaron {filas_afectadas} filas con nulos en {', '.join(nombres_columnas)}.\")\n",
        "\n",
        "    else:\n",
        "        for col in nombres_columnas:\n",
        "            if col not in df_procesado.columns or col not in get_columnas_numericas(df_procesado): # Se corrigi√≥ aqu√≠ tambi√©n\n",
        "                entradas_log.append(f\"Advertencia: La columna '{col}' no es num√©rica o no existe para imputaci√≥n. Se omiti√≥.\")\n",
        "                continue\n",
        "\n",
        "            valor_imputacion = 0\n",
        "            if metodo == \"Llenar con promedio\":\n",
        "                valor_imputacion = df_procesado[col].mean()\n",
        "            elif metodo == \"Llenar con m√°ximo\":\n",
        "                valor_imputacion = df_procesado[col].max()\n",
        "            elif metodo == \"Llenar con m√≠nimo\":\n",
        "                valor_imputacion = df_procesado[col].min()\n",
        "            elif metodo == \"Llenar con cero\":\n",
        "                valor_imputacion = 0\n",
        "\n",
        "            nulos_en_columna = df_procesado[col].isnull().sum()\n",
        "            df_procesado[col] = df_procesado[col].fillna(valor_imputacion)\n",
        "            filas_afectadas += nulos_en_columna # Suma los nulos que realmente se llenaron\n",
        "            entradas_log.append(f\"Limpieza Nulos: La columna '{col}' se imput√≥ con {metodo.split(' ')[-1]} ({valor_imputacion:.2f}).\")\n",
        "\n",
        "    estado_df = df_procesado\n",
        "    mensaje = f\"Limpieza completada. {total_nulos_previos} valores nulos tratados. Registros afectados: {filas_afectadas}.\"\n",
        "    return estado_df, mensaje, gr.Dataframe(value=estado_df.head())"
      ],
      "metadata": {
        "id": "ycg3E7sYzAE9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aplicar_escalado(df_entrada, nombres_columnas_str, metodo_escalado):\n",
        "    \"\"\"II.2 aplicar_escalado: Aplica normalizaci√≥n o estandarizaci√≥n.\"\"\"\n",
        "    global estado_df, entradas_log\n",
        "    df_escalado = df_entrada.copy() if df_entrada is not None else None\n",
        "\n",
        "    if df_escalado is None:\n",
        "        return None, \"Error: Primero cargue un archivo.\", None\n",
        "\n",
        "    nombres_columnas = [c.strip() for c in nombres_columnas_str.split(\",\") if c.strip()]\n",
        "    if not nombres_columnas:\n",
        "        return estado_df, \"Error: Debe especificar al menos una columna num√©rica para escalar.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    if not all(col in df_escalado.columns and col in get_columnas_numericas(df_escalado) for col in nombres_columnas):\n",
        "        return estado_df, \"Error: Verifique que las columnas existan y sean num√©ricas.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    escalador = None\n",
        "    justificacion_escalado = \"\"\n",
        "    if metodo_escalado == \"Min-Max\":\n",
        "        escalador = MinMaxScaler()\n",
        "        justificacion_escalado = \"**Recomendaci√≥n Min-Max:** Se recomienda para algoritmos que esperan un rango acotado (ej. Redes Neuronales) o cuando la distribuci√≥n no es gaussiana. Sin embargo, es sensible a los *outliers* [10-12].\"\n",
        "    elif metodo_escalado == \"Z-Score\":\n",
        "        escalador = StandardScaler()\n",
        "        justificacion_escalado = \"**Recomendaci√≥n Z-Score:** Se recomienda para algoritmos basados en distancias (ej. K-Means, KNN) o cuando se asume una distribuci√≥n aproximadamente normal. Es menos sensible a los *outliers* que Min-Max [10, 12, 13].\"\n",
        "    else:\n",
        "        return estado_df, \"M√©todo de escalado no v√°lido.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    for col in nombres_columnas:\n",
        "        df_escalado[col] = escalador.fit_transform(df_escalado[[col]])\n",
        "        entradas_log.append(f\"Escalado: Columna '{col}' escalada usando {metodo_escalado}.\")\n",
        "\n",
        "    estado_df = df_escalado\n",
        "    mensaje = f\"Escalado de {', '.join(nombres_columnas)} completado usando {metodo_escalado}. {justificacion_escalado}\"\n",
        "    return estado_df, mensaje, gr.Dataframe(value=estado_df.head())"
      ],
      "metadata": {
        "id": "AeIOVC8gzpIK"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detectar_y_tratar_outliers(df_entrada, nombre_columna, tratamiento):\n",
        "    \"\"\"II.3 detectar_y_tratar_outliers: Detecci√≥n por IQR y tratamiento.\"\"\"\n",
        "    global estado_df, entradas_log\n",
        "    df_outliers_tratado = df_entrada.copy() if df_entrada is not None else None\n",
        "\n",
        "    if df_outliers_tratado is None:\n",
        "        return None, \"Error: Primero cargue un archivo.\", None\n",
        "\n",
        "    if nombre_columna not in df_outliers_tratado.columns or nombre_columna not in get_columnas_numericas(df_outliers_tratado):\n",
        "        return estado_df, f\"Error: La columna '{nombre_columna}' no existe o no es num√©rica.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    cuartil_1 = df_outliers_tratado[nombre_columna].quantile(0.25)\n",
        "    cuartil_3 = df_outliers_tratado[nombre_columna].quantile(0.75)\n",
        "    rango_iqr = cuartil_3 - cuartil_1\n",
        "    limite_inferior_iqr = cuartil_1 - 1.5 * rango_iqr\n",
        "    limite_superior_iqr = cuartil_3 + 1.5 * rango_iqr\n",
        "\n",
        "    registros_outliers = df_outliers_tratado[(df_outliers_tratado[nombre_columna] < limite_inferior_iqr) | (df_outliers_tratado[nombre_columna] > limite_superior_iqr)]\n",
        "    numero_outliers = len(registros_outliers)\n",
        "\n",
        "    if numero_outliers == 0:\n",
        "        mensaje = f\"No se detectaron *outliers* en la columna '{nombre_columna}' (M√©todo IQR).\"\n",
        "        return estado_df, mensaje, gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    if tratamiento == \"Eliminar registros\":\n",
        "        df_outliers_tratado = df_outliers_tratado[~((df_outliers_tratado[nombre_columna] < limite_inferior_iqr) | (df_outliers_tratado[nombre_columna] > limite_superior_iqr))]\n",
        "        entradas_log.append(f\"Outliers: Se eliminaron {numero_outliers} *outliers* en '{nombre_columna}'.\")\n",
        "        mensaje = f\"Se detectaron y eliminaron {numero_outliers} *outliers* en '{nombre_columna}'. Se eliminaron {numero_outliers} filas.\"\n",
        "\n",
        "    elif tratamiento == \"Capping (Winsorizaci√≥n)\":\n",
        "        df_outliers_tratado[nombre_columna] = np.where(df_outliers_tratado[nombre_columna] > limite_superior_iqr, limite_superior_iqr, df_outliers_tratado[nombre_columna])\n",
        "        df_outliers_tratado[nombre_columna] = np.where(df_outliers_tratado[nombre_columna] < limite_inferior_iqr, limite_inferior_iqr, df_outliers_tratado[nombre_columna])\n",
        "        entradas_log.append(f\"Outliers: Se aplic√≥ *capping* a {numero_outliers} *outliers* en '{nombre_columna}'.\")\n",
        "        mensaje = f\"Se detectaron {numero_outliers} *outliers* y se aplic√≥ *Capping* (Winsorizaci√≥n) para conservar los registros.\"\n",
        "\n",
        "    else: # \"Informar\"\n",
        "        mensaje = f\"Se detectaron {numero_outliers} *outliers* en '{nombre_columna}'. Se recomienda tratarlos, ya que pueden sesgar la media y la desviaci√≥n est√°ndar [15, 21].\"\n",
        "        estado_df = df_entrada\n",
        "        return estado_df, mensaje, gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    estado_df = df_outliers_tratado\n",
        "    return estado_df, mensaje, gr.Dataframe(value=estado_df.head())"
      ],
      "metadata": {
        "id": "rMskprKR0Joo"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ejecutar_analisis(df_entrada):\n",
        "    \"\"\"III.1 ejecutar_analisis: Calcula estad√≠sticas descriptivas, correlaci√≥n, curtosis y asimetr√≠a.\"\"\"\n",
        "    global entradas_log\n",
        "    if df_entrada is None:\n",
        "        return \"Error: Primero cargue y procese el archivo.\", None\n",
        "\n",
        "    df_numerico = df_entrada.select_dtypes(include=np.number)\n",
        "\n",
        "    if df_numerico.empty:\n",
        "        return \"El DataFrame no contiene columnas num√©ricas para el an√°lisis estad√≠stico.\", None\n",
        "\n",
        "    estadisticas_descriptivas = df_numerico.describe().T\n",
        "    matriz_correlacion = df_numerico.corr(method='pearson')\n",
        "\n",
        "    series_curtosis = df_numerico.apply(kurtosis, fisher=False) # Fisher=False para valor absoluto (Normal=3)\n",
        "    series_asimetria = df_numerico.apply(skew)\n",
        "\n",
        "    df_forma_distribucion = pd.DataFrame({\n",
        "        'Curtosis (Normal ‚âà 3)': series_curtosis,\n",
        "        'Asimetr√≠a (Skewness)': series_asimetria\n",
        "    }).round(3)\n",
        "\n",
        "    texto_interpretacion = \"### Resumen de Interpretaci√≥n:\\n\"\n",
        "    texto_interpretacion += \"- **Curtosis:** Los valores > 3 (Leptoc√∫rtica) indican un pico m√°s agudo y colas pesadas, sugiriendo m√°s *outliers* [30].\\n\"\n",
        "    texto_interpretacion += \"- **Asimetr√≠a:** Valores positivos (> 0) indican sesgo a la derecha (media > mediana) [29, 31].\\n\"\n",
        "    texto_interpretacion += \"- **Correlaci√≥n:** Los valores cercanos a 1 o -1 en el mapa de calor indican relaciones lineales fuertes entre pares de variables [32].\\n\"\n",
        "\n",
        "    entradas_log.append(\"An√°lisis Estad√≠stico: C√°lculos descriptivos, curtosis y asimetr√≠a generados.\")\n",
        "\n",
        "    resumen_analisis_texto = (\n",
        "        f\"{texto_interpretacion}\\n\\n\"\n",
        "        f\"**Estad√≠sticas Descriptivas (Media, Desviaci√≥n, Cuartiles):**\\n{estadisticas_descriptivas.to_markdown()}\\n\\n\"\n",
        "        f\"**Forma de la Distribuci√≥n (Curtosis y Asimetr√≠a):**\\n{df_forma_distribucion.to_markdown()}\\n\"\n",
        "    )\n",
        "\n",
        "    return resumen_analisis_texto, matriz_correlacion"
      ],
      "metadata": {
        "id": "2Ddj2wqk0oYW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generar_graficos(df_entrada, columna_correlacion_heatmap, columna_distribucion_plot):\n",
        "    \"\"\"III.2 generar_graficos: Genera un mapa de calor y un histograma/boxplot.\"\"\"\n",
        "    global entradas_log\n",
        "\n",
        "    if df_entrada is None:\n",
        "        return None, None, \"Error: Primero cargue el archivo.\"\n",
        "\n",
        "    df_numerico = df_entrada.select_dtypes(include=np.number)\n",
        "\n",
        "    if df_numerico.empty:\n",
        "        return None, None, \"Advertencia: No hay columnas num√©ricas para generar gr√°ficos.\"\n",
        "\n",
        "    ruta_plot_correlacion = None\n",
        "    ruta_plot_distribucion = None\n",
        "\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(df_numerico.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "        plt.title(\"Mapa de Calor de Correlaciones (Pearson)\")\n",
        "        ruta_plot_correlacion = \"correlation_plot.png\"\n",
        "        plt.savefig(ruta_plot_correlacion)\n",
        "        plt.close()\n",
        "        entradas_log.append(\"Visualizaci√≥n: Mapa de calor de correlaciones generado.\")\n",
        "    except Exception as e:\n",
        "        entradas_log.append(f\"Error al generar mapa de correlaci√≥n: {e}\")\n",
        "\n",
        "\n",
        "    if columna_distribucion_plot and columna_distribucion_plot in df_numerico.columns:\n",
        "        try:\n",
        "            figura, ejes = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
        "\n",
        "            sns.histplot(df_numerico[columna_distribucion_plot], kde=True, ax=ejes[0])\n",
        "            ejes[0].set_title(f\"Distribuci√≥n de: {columna_distribucion_plot} (Histograma y KDE)\")\n",
        "\n",
        "            sns.boxplot(x=df_numerico[columna_distribucion_plot], ax=ejes[1])\n",
        "            ejes[1].set_title(f\"Boxplot de: {columna_distribucion_plot} (Outliers: 1.5*IQR)\")\n",
        "\n",
        "            plt.tight_layout()\n",
        "            ruta_plot_distribucion = \"distribution_plot.png\"\n",
        "            plt.savefig(ruta_plot_distribucion)\n",
        "            plt.close()\n",
        "            entradas_log.append(f\"Visualizaci√≥n: Gr√°fico de distribuci√≥n para '{columna_distribucion_plot}' generado.\")\n",
        "        except Exception as e:\n",
        "            entradas_log.append(f\"Error al generar gr√°fico de distribuci√≥n para '{columna_distribucion_plot}': {e}\")\n",
        "    else:\n",
        "        entradas_log.append(\"Advertencia: No se pudo generar el gr√°fico de distribuci√≥n, columna no num√©rica o inexistente.\")\n",
        "\n",
        "    return ruta_plot_correlacion, ruta_plot_distribucion, \"Gr√°ficos generados correctamente.\" if ruta_plot_correlacion or ruta_plot_distribucion else \"No se pudo generar ning√∫n gr√°fico.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "LvVmgYiU02DD"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def exportar_resultados(df_entrada, formato_exportacion):\n",
        "    \"\"\"IV.1 exportar_resultados: Permite la exportaci√≥n y genera el reporte de log.\"\"\"\n",
        "    global entradas_log\n",
        "\n",
        "    if df_entrada is None:\n",
        "        return \"Error: No hay datos procesados para exportar.\", None, None\n",
        "\n",
        "    ruta_reporte = \"reporte_analisis.txt\"\n",
        "    contenido_log = \"\\n\".join(entradas_log)\n",
        "\n",
        "    contenido_reporte_final = (\n",
        "        \"### REPORTE BREVE AUTOM√ÅTICO DE PROCESAMIENTO DE DATOS\\n\\n\"\n",
        "        \"**Proceso Seguido y Decisiones Tomadas en Limpieza de Datos:**\\n\"\n",
        "        f\"{contenido_log}\\n\\n\"\n",
        "        f\"**Interpretaci√≥n Preliminar de Resultados Obtenidos:**\\n\"\n",
        "        f\"(La interpretaci√≥n completa de correlaciones, curtosis y regresiones debe realizarla el analista.)\\n\"\n",
        "        f\"Se recomienda revisar el *heatmap* para correlaciones fuertes (Pearson > 0.7 o < -0.7) [32, 38].\\n\"\n",
        "        f\"La limpieza de datos asegura la calidad y reduce el sesgo en fases de modelado posteriores (GIGO: *Garbage In, Garbage Out*) [39].\\n\"\n",
        "        f\"Dimensiones del DataFrame final: {df_entrada.shape}\\n\"\n",
        "    )\n",
        "\n",
        "    with open(ruta_reporte, \"w\") as f:\n",
        "        f.write(contenido_reporte_final)\n",
        "\n",
        "    ruta_salida = None\n",
        "    if formato_exportacion == \"CSV\":\n",
        "        ruta_salida = \"datos_procesados.csv\"\n",
        "        df_entrada.to_csv(ruta_salida, index=False)\n",
        "    elif formato_exportacion == \"Excel\":\n",
        "        ruta_salida = \"datos_procesados.xlsx\"\n",
        "        df_entrada.to_excel(ruta_salida, index=False)\n",
        "    else:\n",
        "        return \"Error: Formato de exportaci√≥n no v√°lido.\", None, None\n",
        "\n",
        "    entradas_log.append(f\"Exportaci√≥n: Datos procesados guardados en {ruta_salida} y Log generado.\")\n",
        "\n",
        "    return f\"Exportaci√≥n exitosa. Descargue el archivo y el reporte.\", ruta_salida, ruta_reporte\n"
      ],
      "metadata": {
        "id": "diuCV09P0_4E"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Estructura de la Interfaz Gradio -----------------\n",
        "\n",
        "with gr.Blocks(title=\"Aplicaci√≥n de Miner√≠a de Datos y EDA\") as interfaz:\n",
        "    gr.Markdown(\"## üõ†Ô∏è Aplicaci√≥n Interactiva para Procesamiento y An√°lisis de Datos\")\n",
        "\n",
        "    estado_df_gradio = gr.State(None)\n",
        "\n",
        "    with gr.Tab(\"1. Carga de Datos\"):\n",
        "        gr.Markdown(\"### Carga y Validaci√≥n del Archivo\")\n",
        "        with gr.Row():\n",
        "            radio_separador = gr.Radio(\n",
        "                choices=[\"Coma (,)\", \"Punto y Coma (;)\"],\n",
        "                label=\"Selecciona el Separador del Archivo\",\n",
        "                value=\"Coma (,)\",\n",
        "                interactive=True\n",
        "            )\n",
        "            input_archivo = gr.File(label=\"Subir Archivo (CSV o Excel)\", interactive=True)\n",
        "\n",
        "        btn_cargar_datos = gr.Button(\"Cargar y Validar\")\n",
        "        msg_carga_datos = gr.Textbox(label=\"Mensaje de Carga\")\n",
        "        df_vista_previa = gr.Dataframe(label=\"Vista Previa (5 primeras filas)\")\n",
        "\n",
        "        btn_cargar_datos.click(\n",
        "            fn=cargar_datos,\n",
        "            inputs=[input_archivo, radio_separador],\n",
        "            outputs=[estado_df_gradio, msg_carga_datos, df_vista_previa]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"2. Procesamiento y Limpieza (Preparaci√≥n de Datos)\"):\n",
        "        gr.Markdown(\"### Limpieza de Valores Nulos\")\n",
        "        with gr.Row():\n",
        "            radio_metodo_nulos = gr.Radio(\n",
        "                choices=[\"Eliminar filas\", \"Llenar con promedio\", \"Llenar con m√°ximo\", \"Llenar con m√≠nimo\", \"Llenar con cero\"],\n",
        "                label=\"M√©todo para manejar nulos [6, 41]\",\n",
        "                value=\"Eliminar filas\"\n",
        "            )\n",
        "            input_col_nulos = gr.Textbox(label=\"Columnas para Limpieza (Separadas por comas)\", placeholder=\"Ej: Col1, Col2 (Dejar vac√≠o para todo el DF)\")\n",
        "\n",
        "        btn_aplicar_nulos = gr.Button(\"Aplicar Limpieza de Nulos\")\n",
        "        msg_resultado_nulos = gr.Textbox(label=\"Resultado Nulos\")\n",
        "\n",
        "        gr.Markdown(\"### Normalizaci√≥n y Estandarizaci√≥n\")\n",
        "        with gr.Row():\n",
        "            radio_metodo_escalado = gr.Radio(\n",
        "                choices=[\"Min-Max\", \"Z-Score\"],\n",
        "                label=\"M√©todo de Escalado [10, 42]\",\n",
        "                value=\"Z-Score\"\n",
        "            )\n",
        "            input_col_escalar = gr.Textbox(label=\"Columnas Num√©ricas para Escalar (Separadas por comas)\", placeholder=\"Ej: Edad, Salario\")\n",
        "\n",
        "        btn_aplicar_escalado = gr.Button(\"Aplicar Normalizaci√≥n / Estandarizaci√≥n\")\n",
        "        msg_resultado_escalado = gr.Textbox(label=\"Resultado Normalizaci√≥n y Justificaci√≥n [10]\")\n",
        "\n",
        "        gr.Markdown(\"### Detecci√≥n y Tratamiento de Outliers (IQR)\")\n",
        "        with gr.Row():\n",
        "            input_col_outliers = gr.Textbox(label=\"Columna para Detecci√≥n de Outliers (Una sola columna)\", placeholder=\"Ej: Ingresos\")\n",
        "            radio_tratamiento_outliers = gr.Radio(\n",
        "                choices=[\"Informar\", \"Eliminar registros\", \"Capping (Winsorizaci√≥n)\"],\n",
        "                label=\"Tratamiento de Outliers [10, 19, 20]\",\n",
        "                value=\"Informar\"\n",
        "            )\n",
        "\n",
        "        btn_detectar_outliers = gr.Button(\"Detectar y Tratar Outliers\")\n",
        "        msg_resultado_outliers = gr.Textbox(label=\"Resultado Outliers\")\n",
        "\n",
        "        btn_aplicar_nulos.click(\n",
        "            fn=manejar_valores_nulos,\n",
        "            inputs=[estado_df_gradio, input_col_nulos, radio_metodo_nulos],\n",
        "            outputs=[estado_df_gradio, msg_resultado_nulos, df_vista_previa]\n",
        "        )\n",
        "        btn_aplicar_escalado.click(\n",
        "            fn=aplicar_escalado,\n",
        "            inputs=[estado_df_gradio, input_col_escalar, radio_metodo_escalado],\n",
        "            outputs=[estado_df_gradio, msg_resultado_escalado, df_vista_previa]\n",
        "        )\n",
        "        btn_detectar_outliers.click(\n",
        "            fn=detectar_y_tratar_outliers,\n",
        "            inputs=[estado_df_gradio, input_col_outliers, radio_tratamiento_outliers],\n",
        "            outputs=[estado_df_gradio, msg_resultado_outliers, df_vista_previa]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"3. An√°lisis y Visualizaci√≥n\"):\n",
        "        gr.Markdown(\"### An√°lisis Estad√≠stico (Correlaci√≥n, Curtosis y Asimetr√≠a) [25]\")\n",
        "\n",
        "        btn_ejecutar_analisis = gr.Button(\"Ejecutar An√°lisis Estad√≠stico\")\n",
        "        output_analisis = gr.Markdown(label=\"Resumen Estad√≠stico e Interpretaci√≥n\")\n",
        "\n",
        "        gr.Markdown(\"### Visualizaci√≥n de Datos Procesados [25]\")\n",
        "        with gr.Row():\n",
        "            input_col_distribucion = gr.Textbox(label=\"Columna para Gr√°fico de Distribuci√≥n (Histograma/Boxplot)\", placeholder=\"Ej: Edad\")\n",
        "\n",
        "        btn_generar_graficos = gr.Button(\"Generar Gr√°ficos\")\n",
        "\n",
        "        with gr.Row():\n",
        "            plot_correlacion = gr.Plot(label=\"Mapa de Calor de Correlaciones\")\n",
        "            plot_distribucion = gr.Plot(label=\"Distribuci√≥n y Outliers (Boxplot/Histograma)\")\n",
        "        msg_graficos = gr.Textbox(label=\"Mensaje de Gr√°ficos\")\n",
        "\n",
        "        btn_ejecutar_analisis.click(\n",
        "            fn=ejecutar_analisis,\n",
        "            inputs=[estado_df_gradio],\n",
        "            outputs=[output_analisis, gr.State(None)]\n",
        "        )\n",
        "        btn_generar_graficos.click(\n",
        "            fn=generar_graficos,\n",
        "            inputs=[estado_df_gradio, gr.State(None), input_col_distribucion],\n",
        "            outputs=[plot_correlacion, plot_distribucion, msg_graficos]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"4. Exportaci√≥n y Reporte\"):\n",
        "        gr.Markdown(\"### Exportar Datos Procesados y Generar Log [36]\")\n",
        "\n",
        "        radio_formato_exportacion = gr.Radio(\n",
        "            choices=[\"CSV\", \"Excel\"],\n",
        "            label=\"Seleccionar Formato de Exportaci√≥n\",\n",
        "            value=\"CSV\"\n",
        "        )\n",
        "\n",
        "        btn_generar_archivos = gr.Button(\"Generar Archivos Finales\")\n",
        "        msg_exportacion = gr.Textbox(label=\"Resultado de la Exportaci√≥n\")\n",
        "\n",
        "        output_archivo_datos = gr.File(label=\"Descargar Datos Procesados\")\n",
        "        output_archivo_log = gr.File(label=\"Descargar Reporte de Log\")\n",
        "\n",
        "        btn_generar_archivos.click(\n",
        "            fn=exportar_resultados,\n",
        "            inputs=[estado_df_gradio, radio_formato_exportacion],\n",
        "            outputs=[msg_exportacion, output_archivo_datos, output_archivo_log]\n",
        "        )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    interfaz.launch(inline=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "ggoZZRhg1dPe",
        "outputId": "c8dfc93e-0d26-4550-dbfe-87d6d272b3a9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7cb3ed577517d23906.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7cb3ed577517d23906.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}