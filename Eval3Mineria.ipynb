{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYhrixUe8Pq7FTo3dvr3OR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Medalcode/Colab1/blob/main/Eval3Mineria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Avance para Retroalimentaci√≥n Evaluacion 3 Mineria de Datos**\n",
        "\n",
        "# **Integrantes: Camila Troncoso - Jonatthan Medalla**"
      ],
      "metadata": {
        "id": "lyG5V24P2psH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gradio as gr\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from scipy.stats import skew, kurtosis\n",
        "import os\n",
        "from io import BytesIO\n",
        "\n",
        "# Install missing dependency\n",
        "!pip install rfc3987"
      ],
      "metadata": {
        "id": "RpE9s8Db2rTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a676170-f08c-42e1-9ecf-06a908d800fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rfc3987\n",
            "  Downloading rfc3987-1.3.8-py2.py3-none-any.whl.metadata (7.5 kB)\n",
            "Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: rfc3987\n",
            "Successfully installed rfc3987-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuraci√≥n inicial para Matplotlib/Seaborn\n",
        "sns.set_theme(style=\"whitegrid\")\n"
      ],
      "metadata": {
        "id": "WlHdnscqyqOW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Variables globales para almacenar el DataFrame y el historial de operaciones (Log)\n",
        "estado_df = None\n",
        "entradas_log = []"
      ],
      "metadata": {
        "id": "FgL05IKHyjdk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_columnas_numericas(df_entrada):\n",
        "    \"\"\"Funci√≥n auxiliar para obtener columnas num√©ricas.\"\"\"\n",
        "    if df_entrada is not None:\n",
        "        return df_entrada.select_dtypes(include=np.number).columns.tolist()\n",
        "    return []\n"
      ],
      "metadata": {
        "id": "ftLC_yuEyzXA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3EC33s5blKY"
      },
      "source": [
        "def cargar_datos(archivo_obj, delimitador_elegido):\n",
        "    \"\"\"I.1 cargar_datos: Carga el archivo subido en un DataFrame.\"\"\"\n",
        "    global estado_df, entradas_log\n",
        "    entradas_log = [] # Reiniciar el log en cada nueva carga para mantener un historial limpio.\n",
        "\n",
        "    if archivo_obj is None:\n",
        "        return None, \"Error: Debe subir un archivo.\", None\n",
        "\n",
        "    ruta_archivo = archivo_obj.name # Obtiene la ruta del archivo subido.\n",
        "\n",
        "    try:\n",
        "        # Procesa archivos CSV\n",
        "        if ruta_archivo.endswith('.csv'):\n",
        "            # Determina el delimitador basado en la selecci√≥n del usuario.\n",
        "            if delimitador_elegido == \"Coma (,)\":\n",
        "                delimitador = ','\n",
        "            elif delimitador_elegido == \"Punto y Coma (;)\":\n",
        "                delimitador = ';'\n",
        "            else:\n",
        "                delimitador = ',' # Delimitador por defecto si no se especifica o es inv√°lido.\n",
        "\n",
        "            # Intentar leer el archivo con codificaciones comunes para manejar diferentes formatos.\n",
        "            try:\n",
        "                df_datos = pd.read_csv(ruta_archivo, delimiter=delimitador, encoding='utf-8')\n",
        "            except UnicodeDecodeError:\n",
        "                df_datos = pd.read_csv(ruta_archivo, delimiter=delimitador, encoding='ISO-8859-1')\n",
        "\n",
        "            # ***** NUEVA L√ìGICA: Detecci√≥n de CSV de una sola columna *****\n",
        "            if df_datos.shape[1] == 1:\n",
        "                estado_df = None\n",
        "                return None, \"Error: El archivo CSV cargado tiene una sola columna. Aseg√∫rese de seleccionar el delimitador correcto o que el archivo contenga m√∫ltiples columnas para un an√°lisis significativo.\", None\n",
        "            # ************************************************************\n",
        "\n",
        "        # Procesa archivos Excel (xls o xlsx)\n",
        "        elif ruta_archivo.endswith(('.xls', '.xlsx')):\n",
        "            df_datos = pd.read_excel(ruta_archivo)\n",
        "\n",
        "        # Maneja tipos de archivo no soportados.\n",
        "        else:\n",
        "            return None, \"Error: Archivo no v√°lido. Suba un archivo CSV o Excel.\", None\n",
        "\n",
        "        # Validaci√≥n de tipos de datos: verifica que el DataFrame contenga columnas categ√≥ricas y num√©ricas.\n",
        "        columnas_numericas = df_datos.select_dtypes(include=np.number).columns\n",
        "        columnas_categoricas = df_datos.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "        # Genera un mensaje de advertencia si faltan tipos de datos importantes para el an√°lisis.\n",
        "        if len(columnas_numericas) == 0 or len(columnas_categoricas) == 0:\n",
        "            mensaje = \"Advertencia: El archivo debe contener tanto datos categ√≥ricos como num√©ricos para un an√°lisis completo.\"\n",
        "        else:\n",
        "            mensaje = f\"Archivo cargado. Dimensiones: {df_datos.shape}. {len(columnas_numericas)} num√©ricas, {len(columnas_categoricas)} categ√≥ricas.\"\n",
        "\n",
        "        estado_df = df_datos # Almacena el DataFrame cargado en la variable de estado global.\n",
        "        # Registra la operaci√≥n de carga en el log.\n",
        "        entradas_log.append(f\"Carga: Archivo {os.path.basename(ruta_archivo)} cargado. Se detectaron {df_datos.shape[0]} filas.\")\n",
        "\n",
        "        # Retorna el DataFrame, el mensaje y una vista previa de las primeras filas.\n",
        "        return estado_df, mensaje, gr.Dataframe(value=df_datos.head())\n",
        "\n",
        "    except Exception as e:\n",
        "        estado_df = None # Reinicia el DataFrame de estado si ocurre un error.\n",
        "        return None, f\"Error de lectura: {str(e)}\", None # Retorna un mensaje de error."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def manejar_valores_nulos(df_entrada, nombres_columnas_str, metodo):\n",
        "    \"\"\"II.1 manejar_valores_nulos: Manejo interactivo de valores nulos.\"\"\"\n",
        "    global estado_df, entradas_log\n",
        "    # Crea una copia del DataFrame de entrada para no modificar el original directamente hasta que la operaci√≥n se confirme.\n",
        "    df_procesado = df_entrada.copy() if df_entrada is not None else None\n",
        "\n",
        "    # Verifica si hay un DataFrame cargado; si no, retorna un error.\n",
        "    if df_procesado is None:\n",
        "        return None, \"Error: Primero cargue un archivo.\", None\n",
        "\n",
        "    # Procesa la cadena de nombres de columnas para obtener una lista, eliminando espacios en blanco.\n",
        "    nombres_columnas = [c.strip() for c in nombres_columnas_str.split(\",\") if c.strip()]\n",
        "    if not nombres_columnas:\n",
        "        # Si el usuario no especific√≥ columnas, aplicar a todas las columnas num√©ricas\n",
        "        nombres_columnas = get_columnas_numericas(df_procesado)\n",
        "        if not nombres_columnas:\n",
        "            return estado_df, \"Advertencia: No hay columnas num√©ricas para aplicar la limpieza de nulos.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Calcula el n√∫mero total de valores nulos antes del tratamiento en las columnas seleccionadas.\n",
        "    total_nulos_previos = df_procesado[nombres_columnas].isnull().sum().sum()\n",
        "    filas_afectadas = 0 # Inicializa el contador de filas o valores afectados.\n",
        "\n",
        "    # Si no hay nulos, no se realiza ninguna operaci√≥n.\n",
        "    if total_nulos_previos == 0:\n",
        "        mensaje = \"No se encontraron valores nulos en las columnas seleccionadas. No se realiz√≥ ninguna operaci√≥n.\"\n",
        "        return estado_df, mensaje, gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Aplica el m√©todo de \"Eliminar filas\" si es seleccionado.\n",
        "    if metodo == \"Eliminar filas\":\n",
        "        total_filas_originales = len(df_procesado)\n",
        "        df_procesado = df_procesado.dropna(subset=nombres_columnas) # Elimina filas con nulos en las columnas especificadas.\n",
        "        filas_afectadas = total_filas_originales - len(df_procesado) # Calcula cu√°ntas filas fueron eliminadas.\n",
        "        # Registra la operaci√≥n en el log.\n",
        "        entradas_log.append(f\"Limpieza Nulos: Se eliminaron {filas_afectadas} filas con nulos en {', '.join(nombres_columnas)}.\")\n",
        "\n",
        "    else:\n",
        "        # Itera sobre cada columna para aplicar los m√©todos de imputaci√≥n.\n",
        "        for col in nombres_columnas:\n",
        "            # Verifica si la columna existe y es num√©rica antes de imputar.\n",
        "            if col not in df_procesado.columns or col not in get_columnas_numericas(df_procesado):\n",
        "                entradas_log.append(f\"Advertencia: La columna '{col}' no es num√©rica o no existe para imputaci√≥n. Se omiti√≥.\")\n",
        "                continue\n",
        "\n",
        "            valor_imputacion = 0 # Valor por defecto para evitar errores si no se selecciona un m√©todo v√°lido.\n",
        "            # Determina el valor de imputaci√≥n seg√∫n el m√©todo seleccionado.\n",
        "            if metodo == \"Llenar con promedio\":\n",
        "                valor_imputacion = df_procesado[col].mean()\n",
        "            elif metodo == \"Llenar con m√°ximo\":\n",
        "                valor_imputacion = df_procesado[col].max()\n",
        "            elif metodo == \"Llenar con m√≠nimo\":\n",
        "                valor_imputacion = df_procesado[col].min()\n",
        "            elif metodo == \"Llenar con cero\":\n",
        "                valor_imputacion = 0\n",
        "\n",
        "            nulos_en_columna = df_procesado[col].isnull().sum() # Cuenta los nulos en la columna actual.\n",
        "            df_procesado[col] = df_procesado[col].fillna(valor_imputacion) # Rellena los nulos con el valor calculado.\n",
        "            filas_afectadas += nulos_en_columna # Suma los nulos que realmente se llenaron.\n",
        "            # Registra la operaci√≥n en el log.\n",
        "            entradas_log.append(f\"Limpieza Nulos: La columna '{col}' se imput√≥ con {metodo.split(' ')[-1]} ({valor_imputacion:.2f}).\")\n",
        "\n",
        "    # Actualiza el DataFrame de estado global con el DataFrame procesado.\n",
        "    estado_df = df_procesado\n",
        "    # Prepara el mensaje de √©xito para el usuario.\n",
        "    mensaje = f\"Limpieza completada. {total_nulos_previos} valores nulos tratados. Registros afectados: {filas_afectadas}.\"\n",
        "    # Retorna el DataFrame actualizado, el mensaje y una vista previa.\n",
        "    return estado_df, mensaje, gr.Dataframe(value=estado_df.head())"
      ],
      "metadata": {
        "id": "ycg3E7sYzAE9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aplicar_escalado(df_entrada, nombres_columnas_str, metodo_escalado):\n",
        "    \"\"\"II.2 aplicar_escalado: Aplica normalizaci√≥n o estandarizaci√≥n.\"\"\"\n",
        "    global estado_df, entradas_log\n",
        "    # Crea una copia del DataFrame de entrada para evitar modificar el original directamente.\n",
        "    df_escalado = df_entrada.copy() if df_entrada is not None else None\n",
        "\n",
        "    # Verifica si hay un DataFrame cargado; si no, retorna un error.\n",
        "    if df_escalado is None:\n",
        "        return None, \"Error: Primero cargue un archivo.\", None\n",
        "\n",
        "    # Procesa la cadena de nombres de columnas para obtener una lista de columnas a escalar.\n",
        "    nombres_columnas = [c.strip() for c in nombres_columnas_str.split(\",\") if c.strip()]\n",
        "    # Si no se especifican columnas, se retorna un error.\n",
        "    if not nombres_columnas:\n",
        "        return estado_df, \"Error: Debe especificar al menos una columna num√©rica para escalar.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Valida que todas las columnas especificadas existan y sean num√©ricas.\n",
        "    if not all(col in df_escalado.columns and col in get_columnas_numericas(df_escalado) for col in nombres_columnas):\n",
        "        return estado_df, \"Error: Verifique que las columnas existan y sean num√©ricas.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    escalador = None # Inicializa la variable del escalador.\n",
        "    justificacion_escalado = \"\" # Inicializa la justificaci√≥n del escalado.\n",
        "    # Selecciona el escalador y la justificaci√≥n seg√∫n el m√©todo elegido.\n",
        "    if metodo_escalado == \"Min-Max\":\n",
        "        escalador = MinMaxScaler() # Utiliza MinMaxScaler para normalizaci√≥n (rango [0, 1]).\n",
        "        justificacion_escalado = \"**Recomendaci√≥n Min-Max:** Se recomienda para algoritmos que esperan un rango acotado (ej. Redes Neuronales) o cuando la distribuci√≥n no es gaussiana. Sin embargo, es sensible a los *outliers* [10-12].\"\n",
        "    elif metodo_escalado == \"Z-Score\":\n",
        "        escalador = StandardScaler() # Utiliza StandardScaler para estandarizaci√≥n (media 0, desviaci√≥n est√°ndar 1).\n",
        "        justificacion_escalado = \"**Recomendaci√≥n Z-Score:** Se recomienda para algoritmos basados en distancias (ej. K-Means, KNN) o cuando se asume una distribuci√≥n aproximadamente normal. Es menos sensible a los *outliers* que Min-Max [10, 12, 13].\"\n",
        "    else:\n",
        "        return estado_df, \"M√©todo de escalado no v√°lido.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Aplica el escalado a cada columna seleccionada.\n",
        "    for col in nombres_columnas:\n",
        "        df_escalado[col] = escalador.fit_transform(df_escalado[[col]]) # Transforma la columna usando el escalador elegido.\n",
        "        entradas_log.append(f\"Escalado: Columna '{col}' escalada usando {metodo_escalado}.\") # Registra la operaci√≥n en el log.\n",
        "\n",
        "    estado_df = df_escalado # Actualiza el DataFrame de estado global con el DataFrame escalado.\n",
        "    # Prepara el mensaje de √©xito para el usuario.\n",
        "    mensaje = f\"Escalado de {', '.join(nombres_columnas)} completado usando {metodo_escalado}. {justificacion_escalado}\"\n",
        "    # Retorna el DataFrame actualizado, el mensaje y una vista previa.\n",
        "    return estado_df, mensaje, gr.Dataframe(value=estado_df.head())"
      ],
      "metadata": {
        "id": "AeIOVC8gzpIK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detectar_y_tratar_outliers(df_entrada, nombre_columna, tratamiento):\n",
        "    \"\"\"II.3 detectar_y_tratar_outliers: Detecci√≥n por IQR y tratamiento.\"\"\"\n",
        "    global estado_df, entradas_log\n",
        "    # Crea una copia del DataFrame de entrada para evitar modificar el original directamente.\n",
        "    df_outliers_tratado = df_entrada.copy() if df_entrada is not None else None\n",
        "\n",
        "    # Verifica si hay un DataFrame cargado; si no, retorna un error.\n",
        "    if df_outliers_tratado is None:\n",
        "        return None, \"Error: Primero cargue un archivo.\", None\n",
        "\n",
        "    # Valida que la columna especificada exista y sea num√©rica.\n",
        "    if nombre_columna not in df_outliers_tratado.columns or nombre_columna not in get_columnas_numericas(df_outliers_tratado):\n",
        "        return estado_df, f\"Error: La columna '{nombre_columna}' no existe o no es num√©rica.\", gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Calcula los cuartiles (Q1 y Q3) de la columna para el m√©todo IQR.\n",
        "    cuartil_1 = df_outliers_tratado[nombre_columna].quantile(0.25)\n",
        "    cuartil_3 = df_outliers_tratado[nombre_columna].quantile(0.75)\n",
        "    # Calcula el Rango Intercuart√≠lico (IQR).\n",
        "    rango_iqr = cuartil_3 - cuartil_1\n",
        "    # Define los l√≠mites inferior y superior para la detecci√≥n de outliers (1.5 * IQR).\n",
        "    limite_inferior_iqr = cuartil_1 - 1.5 * rango_iqr\n",
        "    limite_superior_iqr = cuartil_3 + 1.5 * rango_iqr\n",
        "\n",
        "    # Identifica los registros que son outliers (fuera de los l√≠mites IQR).\n",
        "    registros_outliers = df_outliers_tratado[(df_outliers_tratado[nombre_columna] < limite_inferior_iqr) | (df_outliers_tratado[nombre_columna] > limite_superior_iqr)]\n",
        "    numero_outliers = len(registros_outliers)\n",
        "\n",
        "    # Si no se detectan outliers, informa al usuario y no realiza ninguna acci√≥n.\n",
        "    if numero_outliers == 0:\n",
        "        mensaje = f\"No se detectaron *outliers* en la columna '{nombre_columna}' (M√©todo IQR).\"\n",
        "        return estado_df, mensaje, gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Aplica el tratamiento seleccionado por el usuario.\n",
        "    if tratamiento == \"Eliminar registros\":\n",
        "        # Filtra el DataFrame para eliminar las filas que contienen outliers.\n",
        "        df_outliers_tratado = df_outliers_tratado[~((df_outliers_tratado[nombre_columna] < limite_inferior_iqr) | (df_outliers_tratado[nombre_columna] > limite_superior_iqr))]\n",
        "        # Registra la operaci√≥n en el log.\n",
        "        entradas_log.append(f\"Outliers: Se eliminaron {numero_outliers} *outliers* en '{nombre_columna}'.\")\n",
        "        mensaje = f\"Se detectaron y eliminaron {numero_outliers} *outliers* en '{nombre_columna}'. Se eliminaron {numero_outliers} filas.\"\n",
        "\n",
        "    elif tratamiento == \"Capping (Winsorizaci√≥n)\":\n",
        "        # Limita los valores at√≠picos a los umbrales IQR (Winsorizaci√≥n).\n",
        "        df_outliers_tratado[nombre_columna] = np.where(df_outliers_tratado[nombre_columna] > limite_superior_iqr, limite_superior_iqr, df_outliers_tratado[nombre_columna])\n",
        "        df_outliers_tratado[nombre_columna] = np.where(df_outliers_tratado[nombre_columna] < limite_inferior_iqr, limite_inferior_iqr, df_outliers_tratado[nombre_columna])\n",
        "        # Registra la operaci√≥n en el log.\n",
        "        entradas_log.append(f\"Outliers: Se aplic√≥ *capping* a {numero_outliers} *outliers* en '{nombre_columna}'.\")\n",
        "        mensaje = f\"Se detectaron {numero_outliers} *outliers* y se aplic√≥ *Capping* (Winsorizaci√≥n) para conservar los registros.\"\n",
        "\n",
        "    else: # Opci√≥n \"Informar\"\n",
        "        # Simplemente informa sobre la presencia de outliers sin modificarlos.\n",
        "        mensaje = f\"Se detectaron {numero_outliers} *outliers* en '{nombre_columna}'. Se recomienda tratarlos, ya que pueden sesgar la media y la desviaci√≥n est√°ndar [15, 21].\"\n",
        "        estado_df = df_entrada # No se modifica el DataFrame si solo se informa.\n",
        "        return estado_df, mensaje, gr.Dataframe(value=estado_df.head())\n",
        "\n",
        "    # Actualiza el DataFrame de estado global con el DataFrame procesado.\n",
        "    estado_df = df_outliers_tratado\n",
        "    # Retorna el DataFrame actualizado, el mensaje y una vista previa.\n",
        "    return estado_df, mensaje, gr.Dataframe(value=estado_df.head())"
      ],
      "metadata": {
        "id": "rMskprKR0Joo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ejecutar_analisis(df_entrada):\n",
        "    \"\"\"III.1 ejecutar_analisis: Calcula estad√≠sticas descriptivas, correlaci√≥n, curtosis y asimetr√≠a.\"\"\"\n",
        "    global entradas_log\n",
        "    # Verifica si hay un DataFrame cargado; si no, retorna un error.\n",
        "    if df_entrada is None:\n",
        "        return \"Error: Primero cargue y procese el archivo.\", None\n",
        "\n",
        "    # Selecciona solo las columnas num√©ricas del DataFrame para el an√°lisis.\n",
        "    df_numerico = df_entrada.select_dtypes(include=np.number)\n",
        "\n",
        "    # Verifica si existen columnas num√©ricas en el DataFrame.\n",
        "    if df_numerico.empty:\n",
        "        return \"El DataFrame no contiene columnas num√©ricas para el an√°lisis estad√≠stico.\", None\n",
        "\n",
        "    # Calcula las estad√≠sticas descriptivas (media, desviaci√≥n est√°ndar, cuartiles, etc.).\n",
        "    estadisticas_descriptivas = df_numerico.describe().T\n",
        "    # Calcula la matriz de correlaci√≥n de Pearson entre las columnas num√©ricas.\n",
        "    matriz_correlacion = df_numerico.corr(method='pearson')\n",
        "\n",
        "    # Calcula la curtosis de cada columna num√©rica (Fisher=False para que la normal sea 3).\n",
        "    series_curtosis = df_numerico.apply(kurtosis, fisher=False)\n",
        "    # Calcula la asimetr√≠a (skewness) de cada columna num√©rica.\n",
        "    series_asimetria = df_numerico.apply(skew)\n",
        "\n",
        "    # Combina los resultados de curtosis y asimetr√≠a en un solo DataFrame.\n",
        "    df_forma_distribucion = pd.DataFrame({\n",
        "        'Curtosis (Normal ‚âà 3)': series_curtosis,\n",
        "        'Asimetr√≠a (Skewness)': series_asimetria\n",
        "    }).round(3)\n",
        "\n",
        "    # Prepara el texto de interpretaci√≥n de los resultados.\n",
        "    texto_interpretacion = \"### Resumen de Interpretaci√≥n:\\n\"\n",
        "    texto_interpretacion += \"- **Curtosis:** Los valores > 3 (Leptoc√∫rtica) indican un pico m√°s agudo y colas pesadas, sugiriendo m√°s *outliers* [30].\\n\"\n",
        "    texto_interpretacion += \"- **Asimetr√≠a:** Valores positivos (> 0) indican sesgo a la derecha (media > mediana) [29, 31].\\n\"\n",
        "    texto_interpretacion += \"- **Correlaci√≥n:** Los valores cercanos a 1 o -1 en el mapa de calor indican relaciones lineales fuertes entre pares de variables [32].\\n\"\n",
        "\n",
        "    # Registra la operaci√≥n de an√°lisis en el log.\n",
        "    entradas_log.append(\"An√°lisis Estad√≠stico: C√°lculos descriptivos, curtosis y asimetr√≠a generados.\")\n",
        "\n",
        "    # Formatea el resumen del an√°lisis para mostrarlo al usuario.\n",
        "    resumen_analisis_texto = (\n",
        "        f\"{texto_interpretacion}\\n\\n\"\n",
        "        f\"**Estad√≠sticas Descriptivas (Media, Desviaci√≥n, Cuartiles):**\\n{estadisticas_descriptivas.to_markdown()}\\n\\n\"\n",
        "        f\"**Forma de la Distribuci√≥n (Curtosis y Asimetr√≠a):**\\n{df_forma_distribucion.to_markdown()}\\n\"\n",
        "    )\n",
        "\n",
        "    # Retorna el resumen en texto y la matriz de correlaci√≥n (esta √∫ltima para posible uso interno o visualizaci√≥n).\n",
        "    return resumen_analisis_texto, matriz_correlacion"
      ],
      "metadata": {
        "id": "2Ddj2wqk0oYW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generar_graficos(df_entrada, columna_correlacion_heatmap, columna_distribucion_plot):\n",
        "    \"\"\"III.2 generar_graficos: Genera un mapa de calor y un histograma/boxplot.\"\"\"\n",
        "    global entradas_log\n",
        "\n",
        "    # Verifica si hay un DataFrame cargado; si no, retorna un error.\n",
        "    if df_entrada is None:\n",
        "        return None, None, \"Error: Primero cargue el archivo.\"\n",
        "\n",
        "    # Selecciona solo las columnas num√©ricas del DataFrame para la generaci√≥n de gr√°ficos.\n",
        "    df_numerico = df_entrada.select_dtypes(include=np.number)\n",
        "\n",
        "    # Si no hay columnas num√©ricas, advierte al usuario.\n",
        "    if df_numerico.empty:\n",
        "        return None, None, \"Advertencia: No hay columnas num√©ricas para generar gr√°ficos.\"\n",
        "\n",
        "    ruta_plot_correlacion = None\n",
        "    ruta_plot_distribucion = None\n",
        "\n",
        "    try:\n",
        "        # Crea una figura para el mapa de calor de correlaciones.\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        # Genera el mapa de calor usando Seaborn, mostrando los valores de correlaci√≥n y una paleta de color.\n",
        "        sns.heatmap(df_numerico.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "        plt.title(\"Mapa de Calor de Correlaciones (Pearson)\")\n",
        "        # Guarda el mapa de calor como una imagen PNG.\n",
        "        ruta_plot_correlacion = \"correlation_plot.png\"\n",
        "        plt.savefig(ruta_plot_correlacion)\n",
        "        plt.close() # Cierra la figura para liberar memoria.\n",
        "        entradas_log.append(\"Visualizaci√≥n: Mapa de calor de correlaciones generado.\") # Registra la operaci√≥n.\n",
        "    except Exception as e:\n",
        "        entradas_log.append(f\"Error al generar mapa de correlaci√≥n: {e}\") # Registra cualquier error.\n",
        "\n",
        "    # Verifica si se ha especificado una columna para el gr√°fico de distribuci√≥n y si esta es num√©rica.\n",
        "    if columna_distribucion_plot and columna_distribucion_plot in df_numerico.columns:\n",
        "        try:\n",
        "            # Crea una figura con dos subplots para el histograma y el boxplot.\n",
        "            figura, ejes = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
        "\n",
        "            # Genera un histograma con la funci√≥n de densidad de kernel (KDE) para mostrar la distribuci√≥n.\n",
        "            sns.histplot(df_numerico[columna_distribucion_plot], kde=True, ax=ejes[0])\n",
        "            ejes[0].set_title(f\"Distribuci√≥n de: {columna_distribucion_plot} (Histograma y KDE)\")\n",
        "\n",
        "            # Genera un boxplot para visualizar la distribuci√≥n, la mediana y los posibles outliers.\n",
        "            sns.boxplot(x=df_numerico[columna_distribucion_plot], ax=ejes[1])\n",
        "            ejes[1].set_title(f\"Boxplot de: {columna_distribucion_plot} (Outliers: 1.5*IQR)\")\n",
        "\n",
        "            plt.tight_layout() # Ajusta el dise√±o para evitar superposiciones.\n",
        "            # Guarda los gr√°ficos de distribuci√≥n como una imagen PNG.\n",
        "            ruta_plot_distribucion = \"distribution_plot.png\"\n",
        "            plt.savefig(ruta_plot_distribucion)\n",
        "            plt.close() # Cierra la figura para liberar memoria.\n",
        "            entradas_log.append(f\"Visualizaci√≥n: Gr√°fico de distribuci√≥n para '{columna_distribucion_plot}' generado.\") # Registra la operaci√≥n.\n",
        "        except Exception as e:\n",
        "            entradas_log.append(f\"Error al generar gr√°fico de distribuci√≥n para '{columna_distribucion_plot}': {e}\") # Registra cualquier error.\n",
        "    else:\n",
        "        entradas_log.append(\"Advertencia: No se pudo generar el gr√°fico de distribuci√≥n, columna no num√©rica o inexistente.\")\n",
        "\n",
        "    # Retorna las rutas de los archivos generados y un mensaje de estado.\n",
        "    return ruta_plot_correlacion, ruta_plot_distribucion, \"Gr√°ficos generados correctamente.\" if ruta_plot_correlacion or ruta_plot_distribucion else \"No se pudo generar ning√≥n gr√°fico.\"\n"
      ],
      "metadata": {
        "id": "LvVmgYiU02DD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exportar_resultados(df_entrada, formato_exportacion):\n",
        "    \"\"\"IV.1 exportar_resultados: Permite la exportaci√≥n y genera el reporte de log.\"\"\"\n",
        "    global entradas_log\n",
        "\n",
        "    # Verifica si hay un DataFrame procesado; si no, retorna un error.\n",
        "    if df_entrada is None:\n",
        "        return \"Error: No hay datos procesados para exportar.\", None, None\n",
        "\n",
        "    ruta_reporte = \"reporte_analisis.txt\" # Define el nombre del archivo del reporte.\n",
        "    contenido_log = \"\\n\".join(entradas_log) # Concatena todas las entradas del log en una cadena.\n",
        "\n",
        "    # Prepara el contenido final del reporte incluyendo un resumen autom√°tico y la interpretaci√≥n.\n",
        "    contenido_reporte_final = (\n",
        "        \"### REPORTE BREVE AUTOM√ÅTICO DE PROCESAMIENTO DE DATOS\\n\\n\"\n",
        "        \"**Proceso Seguido y Decisiones Tomadas en Limpieza de Datos:**\\n\"\n",
        "        f\"{contenido_log}\\n\\n\"\n",
        "        f\"**Interpretaci√≥n Preliminar de Resultados Obtenidos:**\\n\"\n",
        "        f\"(La interpretaci√≥n completa de correlaciones, curtosis y regresiones debe realizarla el analista.)\\n\"\n",
        "        f\"Se recomienda revisar el *heatmap* para correlaciones fuertes (Pearson > 0.7 o < -0.7) [32, 38].\\n\"\n",
        "        f\"La limpieza de datos asegura la calidad y reduce el sesgo en fases de modelado posteriores (GIGO: *Garbage In, Garbage Out*) [39].\\n\"\n",
        "        f\"Dimensiones del DataFrame final: {df_entrada.shape}\\n\"\n",
        "    )\n",
        "\n",
        "    # Escribe el contenido del reporte en un archivo de texto.\n",
        "    with open(ruta_reporte, \"w\") as f:\n",
        "        f.write(contenido_reporte_final)\n",
        "\n",
        "    ruta_salida = None # Inicializa la ruta del archivo de datos procesados.\n",
        "    # Exporta el DataFrame procesado seg√∫n el formato seleccionado.\n",
        "    if formato_exportacion == \"CSV\":\n",
        "        ruta_salida = \"datos_procesados.csv\"\n",
        "        df_entrada.to_csv(ruta_salida, index=False) # Exporta a CSV sin el √≠ndice del DataFrame.\n",
        "    elif formato_exportacion == \"Excel\":\n",
        "        ruta_salida = \"datos_procesados.xlsx\"\n",
        "        df_entrada.to_excel(ruta_salida, index=False) # Exporta a Excel sin el √≠ndice del DataFrame.\n",
        "    else:\n",
        "        return \"Error: Formato de exportaci√≥n no v√°lido.\", None, None # Retorna un error si el formato no es v√°lido.\n",
        "\n",
        "    # Registra la operaci√≥n de exportaci√≥n en el log.\n",
        "    entradas_log.append(f\"Exportaci√≥n: Datos procesados guardados en {ruta_salida} y Log generado.\")\n",
        "\n",
        "    # Retorna un mensaje de √©xito, la ruta del archivo de datos y la ruta del reporte.\n",
        "    return f\"Exportaci√≥n exitosa. Descargue el archivo y el reporte.\", ruta_salida, ruta_reporte\n"
      ],
      "metadata": {
        "id": "diuCV09P0_4E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_dropdown_choices(df_entrada):\n",
        "    \"\"\"Actualiza las opciones del dropdown de columnas num√©ricas en la interfaz de Gradio.\"\"\"\n",
        "    if df_entrada is not None:\n",
        "        # Asume que get_columnas_numericas ya est√° definida en otra celda y accesible.\n",
        "        numeric_cols = get_columnas_numericas(df_entrada)\n",
        "        # Retorna un componente Dropdown actualizado con las columnas num√©ricas como opciones.\n",
        "        # Si hay columnas, selecciona la primera por defecto; de lo contrario, deja el valor en None.\n",
        "        return gr.Dropdown(choices=numeric_cols, value=numeric_cols[0] if numeric_cols else None)\n",
        "    # Si no hay DataFrame, retorna un Dropdown vac√≠o.\n",
        "    return gr.Dropdown(choices=[], value=None)"
      ],
      "metadata": {
        "id": "u4L9w-yoA78Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks(title=\"Aplicaci√≥n de Miner√≠a de Datos y EDA\") as interfaz:\n",
        "    gr.Markdown(\"## üî®Ô∏è Aplicaci√≥n Interactiva para Procesamiento y An√°lisis de Datos\")\n",
        "\n",
        "    estado_df_gradio = gr.State(None)\n",
        "\n",
        "    with gr.Tab(\"1. Carga de Datos\"):\n",
        "        gr.Markdown(\"### Carga y Validaci√≥n del Archivo\")\n",
        "        with gr.Row():\n",
        "            # Componente para subir el archivo (CSV o Excel).\n",
        "            input_archivo = gr.File(label=\"Subir Archivo (CSV o Excel)\", interactive=True)\n",
        "            # Radio buttons para seleccionar el delimitador del archivo CSV.\n",
        "            radio_separador = gr.Radio(\n",
        "                choices=[\"Coma (,)\", \"Punto y Coma (;)\"],\n",
        "                label=\"Selecciona el Separador del Archivo\",\n",
        "                value=\"Coma (,)\",\n",
        "                interactive=True\n",
        "            )\n",
        "\n",
        "        btn_cargar_datos = gr.Button(\"Cargar y Validar\")\n",
        "        msg_carga_datos = gr.Textbox(label=\"Mensaje de Carga\")\n",
        "        df_vista_previa = gr.Dataframe(label=\"Vista Previa (5 primeras filas)\")\n",
        "\n",
        "    with gr.Tab(\"2. Procesamiento y Limpieza (Preparaci√≥n de Datos)\"):\n",
        "        gr.Markdown(\"### Limpieza de Valores Nulos\")\n",
        "        with gr.Row():\n",
        "            radio_metodo_nulos = gr.Radio(\n",
        "                choices=[\"Eliminar filas\", \"Llenar con promedio\", \"Llenar con m√°ximo\", \"Llenar con m√≠nimo\", \"Llenar con cero\"],\n",
        "                label=\"M√©todo para manejar nulos [6, 41]\",\n",
        "                value=\"Eliminar filas\"\n",
        "            )\n",
        "            input_col_nulos = gr.Textbox(label=\"Columnas para Limpieza (Separadas por comas)\", placeholder=\"Ej: Col1, Col2 (Dejar vac√≠o para todo el DF)\")\n",
        "\n",
        "        btn_aplicar_nulos = gr.Button(\"Aplicar Limpieza de Nulos\")\n",
        "        msg_resultado_nulos = gr.Textbox(label=\"Resultado Nulos\")\n",
        "\n",
        "        gr.Markdown(\"### Normalizaci√≥n y Estandarizaci√≥n\")\n",
        "        with gr.Row():\n",
        "            radio_metodo_escalado = gr.Radio(\n",
        "                choices=[\"Min-Max\", \"Z-Score\"],\n",
        "                label=\"M√©todo de Escalado [10, 42]\",\n",
        "                value=\"Z-Score\"\n",
        "            )\n",
        "            input_col_escalar = gr.Textbox(label=\"Columnas Num√©ricas para Escalar (Separadas por comas)\", placeholder=\"Ej: Edad, Salario\")\n",
        "\n",
        "        btn_aplicar_escalado = gr.Button(\"Aplicar Normalizaci√≥n / Estandarizaci√≥n\")\n",
        "        msg_resultado_escalado = gr.Textbox(label=\"Resultado Normalizaci√≥n y Justificaci√≥n [10]\")\n",
        "\n",
        "        gr.Markdown(\"### Detecci√≥n y Tratamiento de Outliers (IQR)\")\n",
        "        with gr.Row():\n",
        "            input_col_outliers = gr.Textbox(label=\"Columna para Detecci√≥n de Outliers (Una sola columna)\", placeholder=\"Ej: Ingresos\")\n",
        "            radio_tratamiento_outliers = gr.Radio(\n",
        "                choices=[\"Informar\", \"Eliminar registros\", \"Capping (Winsorizaci√≥n)\"],\n",
        "                label=\"Tratamiento de Outliers [10, 19, 20]\",\n",
        "                value=\"Informar\"\n",
        "            )\n",
        "\n",
        "        btn_detectar_outliers = gr.Button(\"Detectar y Tratar Outliers\")\n",
        "        msg_resultado_outliers = gr.Textbox(label=\"Resultado Outliers\")\n",
        "\n",
        "    with gr.Tab(\"3. An√°lisis y Visualizaci√≥n\"):\n",
        "        gr.Markdown(\"### An√°lisis Estad√≠stico (Correlaci√≥n, Curtosis y Asimetr√≠a) [25]\")\n",
        "\n",
        "        output_analisis = gr.Markdown(label=\"Resumen Estad√≠stico e Interpretaci√≥n\")\n",
        "        btn_ejecutar_analisis = gr.Button(\"Ejecutar An√°lisis Estad√≠stico\")\n",
        "\n",
        "        gr.Markdown(\"### Visualizaci√≥n de Datos Procesados [25]\")\n",
        "        with gr.Row():\n",
        "            input_col_distribucion = gr.Dropdown(label=\"Columna para Gr√°fico de Distribuci√≥n (Histograma/Boxplot)\", choices=[], interactive=True)\n",
        "\n",
        "        btn_generar_graficos = gr.Button(\"Generar Gr√°ficos\")\n",
        "\n",
        "        with gr.Row():\n",
        "            plot_correlacion = gr.Plot(label=\"Mapa de Calor de Correlaciones\")\n",
        "            plot_distribucion = gr.Plot(label=\"Distribuci√≥n y Outliers (Boxplot/Histograma)\")\n",
        "        msg_graficos = gr.Textbox(label=\"Mensaje de Gr√°ficos\")\n",
        "\n",
        "    with gr.Tab(\"4. Exportaci√≥n y Reporte\"):\n",
        "        gr.Markdown(\"### Exportar Datos Procesados y Generar Log [36]\")\n",
        "\n",
        "        radio_formato_exportacion = gr.Radio(\n",
        "            choices=[\"CSV\", \"Excel\"],\n",
        "            label=\"Seleccionar Formato de Exportaci√≥n\",\n",
        "            value=\"CSV\"\n",
        "        )\n",
        "\n",
        "        btn_generar_archivos = gr.Button(\"Generar Archivos Finales\")\n",
        "        msg_exportacion = gr.Textbox(label=\"Resultado de la Exportaci√≥n\")\n",
        "\n",
        "        output_archivo_datos = gr.File(label=\"Descargar Datos Procesados\")\n",
        "        output_archivo_log = gr.File(label=\"Descargar Reporte de Log\")\n",
        "\n",
        "    btn_cargar_datos.click(\n",
        "        fn=cargar_datos,\n",
        "        inputs=[input_archivo, radio_separador],\n",
        "        outputs=[estado_df_gradio, msg_carga_datos, df_vista_previa]\n",
        "    ).success(\n",
        "        fn=update_dropdown_choices,\n",
        "        inputs=[estado_df_gradio],\n",
        "        outputs=[input_col_distribucion]\n",
        "    )\n",
        "\n",
        "    btn_aplicar_nulos.click(\n",
        "        fn=manejar_valores_nulos,\n",
        "        inputs=[estado_df_gradio, input_col_nulos, radio_metodo_nulos],\n",
        "        outputs=[estado_df_gradio, msg_resultado_nulos, df_vista_previa]\n",
        "    ).success(\n",
        "        fn=update_dropdown_choices,\n",
        "        inputs=[estado_df_gradio],\n",
        "        outputs=[input_col_distribucion]\n",
        "    )\n",
        "\n",
        "    btn_aplicar_escalado.click(\n",
        "        fn=aplicar_escalado,\n",
        "        inputs=[estado_df_gradio, input_col_escalar, radio_metodo_escalado],\n",
        "        outputs=[estado_df_gradio, msg_resultado_escalado, df_vista_previa]\n",
        "    ).success(\n",
        "        fn=update_dropdown_choices,\n",
        "        inputs=[estado_df_gradio],\n",
        "        outputs=[input_col_distribucion]\n",
        "    )\n",
        "\n",
        "    btn_detectar_outliers.click(\n",
        "        fn=detectar_y_tratar_outliers,\n",
        "        inputs=[estado_df_gradio, input_col_outliers, radio_tratamiento_outliers],\n",
        "        outputs=[estado_df_gradio, msg_resultado_outliers, df_vista_previa]\n",
        "    ).success(\n",
        "        fn=update_dropdown_choices,\n",
        "        inputs=[estado_df_gradio],\n",
        "        outputs=[input_col_distribucion]\n",
        "    )\n",
        "\n",
        "    btn_ejecutar_analisis.click(\n",
        "        fn=ejecutar_analisis,\n",
        "        inputs=[estado_df_gradio],\n",
        "        outputs=[output_analisis, gr.State(None)]\n",
        "    )\n",
        "\n",
        "    btn_generar_graficos.click(\n",
        "        fn=generar_graficos,\n",
        "        inputs=[estado_df_gradio, gr.State(None), input_col_distribucion],\n",
        "        outputs=[plot_correlacion, plot_distribucion, msg_graficos]\n",
        "    )\n",
        "\n",
        "    btn_generar_archivos.click(\n",
        "        fn=exportar_resultados,\n",
        "        inputs=[estado_df_gradio, radio_formato_exportacion],\n",
        "        outputs=[msg_exportacion, output_archivo_datos, output_archivo_log]\n",
        "    )"
      ],
      "metadata": {
        "id": "ggoZZRhg1dPe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Inicia la interfaz Gradio si el script se ejecuta directamente.\n",
        "if __name__ == \"__main__\":\n",
        "    interfaz.launch(inline=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "6ae4c372-4f69-42de-fa70-031d028fa98b",
        "id": "OJrbjig4DpXc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8b2e8c22c4b3170c36.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8b2e8c22c4b3170c36.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}